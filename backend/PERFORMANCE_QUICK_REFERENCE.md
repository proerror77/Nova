# Performance Optimization Quick Reference

**ä¸€é¡µé€ŸæŸ¥æ‰‹å†Œ** - æ‰€æœ‰å…³é”®æ€§èƒ½æ¨¡å¼å’Œåæ¨¡å¼

---

## ğŸš¨ Critical Anti-Patterns (ç«‹å³ä¿®å¤)

### âŒ N+1 Query Problem
```rust
// BAD: å¾ªç¯ä¸­æŸ¥è¯¢æ•°æ®åº“
for user_id in user_ids {
    let user = query!("SELECT * FROM users WHERE id = $1", user_id)
        .fetch_one(pool).await?;
}

// GOOD: æ‰¹é‡æŸ¥è¯¢
let users = query!("SELECT * FROM users WHERE id = ANY($1)", &user_ids)
    .fetch_all(pool).await?;
```

### âŒ No Connection Pool Timeouts
```rust
// BAD: æ— è¶…æ—¶é…ç½®
PgPoolOptions::new()
    .max_connections(50)
    .connect(&url).await?;

// GOOD: å®Œæ•´è¶…æ—¶é…ç½®
PgPoolOptions::new()
    .max_connections(50)
    .acquire_timeout(Duration::from_secs(10))
    .idle_timeout(Duration::from_secs(600))
    .max_lifetime(Duration::from_secs(1800))
    .connect(&url).await?;
```

### âŒ Missing Cache Layer
```rust
// BAD: æ¯æ¬¡éƒ½æŸ¥è¯¢æ•°æ®åº“
let user = db.get_user(id).await?;

// GOOD: ç¼“å­˜åŒ…è£…
if let Some(user) = cache.get(&key).await? {
    return Ok(user);
}
let user = db.get_user(id).await?;
cache.set(&key, &user).await?;
```

### âŒ Blocking in Async Code
```rust
// BAD: é˜»å¡ async æ‰§è¡Œå™¨
async fn handler() {
    let data = std::fs::read("file.txt")?;  // é˜»å¡!
}

// GOOD: ä½¿ç”¨ async I/O
async fn handler() {
    let data = tokio::fs::read("file.txt").await?;
}

// GOOD: CPU å¯†é›†ä»»åŠ¡ç”¨ spawn_blocking
async fn handler() {
    let result = tokio::task::spawn_blocking(|| {
        expensive_computation()
    }).await?;
}
```

---

## âœ… Database Optimization Patterns

### 1. Covering Indexes (é¿å…è¡¨å›æŸ¥)
```sql
-- BAD: æ™®é€šç´¢å¼• (éœ€è¦å›è¡¨)
CREATE INDEX idx_user_created ON posts(user_id);

-- GOOD: è¦†ç›–ç´¢å¼• (åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—)
CREATE INDEX idx_user_created_covering ON posts(user_id)
INCLUDE (id, content, created_at);
```

### 2. Partial Indexes (å‡å°‘ç´¢å¼•å¤§å°)
```sql
-- BAD: ç´¢å¼•æ‰€æœ‰è¡Œ
CREATE INDEX idx_posts_created ON posts(created_at);

-- GOOD: åªç´¢å¼•æ´»è·ƒæ•°æ®
CREATE INDEX idx_posts_active ON posts(created_at)
WHERE soft_delete IS NULL AND created_at > NOW() - INTERVAL '30 days';
```

### 3. Keyset Pagination (æ·±åˆ†é¡µä¼˜åŒ–)
```rust
// BAD: OFFSET åˆ†é¡µ (æ·±åˆ†é¡µæ…¢)
query!("SELECT * FROM posts ORDER BY created_at DESC LIMIT $1 OFFSET $2",
    limit, page * limit)

// GOOD: Keyset åˆ†é¡µ (åŸºäºæ¸¸æ ‡)
query!("SELECT * FROM posts WHERE created_at < $1 ORDER BY created_at DESC LIMIT $2",
    cursor_timestamp, limit)
```

### 4. Batch Inserts (å‡å°‘å¾€è¿”)
```rust
// BAD: é€ä¸ªæ’å…¥
for post in posts {
    query!("INSERT INTO posts (...) VALUES (...)", post).execute(pool).await?;
}

// GOOD: æ‰¹é‡æ’å…¥
query!("INSERT INTO posts (...) SELECT * FROM UNNEST($1)", &posts)
    .execute(pool).await?;
```

---

## ğŸ”„ Caching Patterns

### 1. Cache-Aside (Lazy Loading)
```rust
async fn get_user_cached(cache: &Cache, db: &Db, id: &str) -> Result<User> {
    let key = format!("user:{}", id);

    // L2: Redis
    if let Some(user) = cache.get(&key).await? {
        return Ok(user);
    }

    // DB fallback
    let user = db.get_user(id).await?;
    cache.set(&key, &user, 600).await?;

    Ok(user)
}
```

### 2. Write-Through (å†™å…¥åŒæ­¥æ›´æ–°)
```rust
async fn update_user(cache: &Cache, db: &Db, user: User) -> Result<()> {
    // å†™æ•°æ®åº“
    db.update_user(&user).await?;

    // åŒæ­¥æ›´æ–°ç¼“å­˜
    let key = format!("user:{}", user.id);
    cache.set(&key, &user, 600).await?;

    Ok(())
}
```

### 3. Cache Stampede Prevention (é˜²æ­¢ç¼“å­˜å‡»ç©¿)
```rust
use tokio::sync::Mutex;
use std::collections::HashMap;

lazy_static::lazy_static! {
    static ref REFRESH_LOCKS: Mutex<HashMap<String, Arc<Mutex<()>>>> =
        Mutex::new(HashMap::new());
}

async fn get_with_stampede_protection(
    cache: &Cache,
    db: &Db,
    key: &str,
) -> Result<User> {
    // å°è¯•ä»ç¼“å­˜è·å–
    if let Some(user) = cache.get(key).await? {
        return Ok(user);
    }

    // è·å–åˆ·æ–°é” (åŒä¸€ key åªæœ‰ä¸€ä¸ªè¯·æ±‚åˆ·æ–°)
    let lock = {
        let mut locks = REFRESH_LOCKS.lock().await;
        locks.entry(key.to_string())
            .or_insert_with(|| Arc::new(Mutex::new(())))
            .clone()
    };

    let _guard = lock.lock().await;

    // å†æ¬¡æ£€æŸ¥ç¼“å­˜ (å¯èƒ½å·²è¢«å…¶ä»–çº¿ç¨‹åˆ·æ–°)
    if let Some(user) = cache.get(key).await? {
        return Ok(user);
    }

    // æŸ¥è¯¢æ•°æ®åº“å¹¶æ›´æ–°ç¼“å­˜
    let user = db.get_user(key).await?;
    cache.set(key, &user, 600).await?;

    Ok(user)
}
```

---

## âš¡ gRPC Optimization

### 1. Connection Pooling with Timeouts
```rust
let channel = Channel::from_shared(uri)?
    .connect_timeout(Duration::from_secs(3))
    .timeout(Duration::from_secs(5))
    .http2_keep_alive_interval(Duration::from_secs(30))
    .keep_alive_timeout(Duration::from_secs(60))
    .connect().await?;
```

### 2. Batch Requests (å‡å°‘å¾€è¿”)
```rust
// BAD: é€ä¸ªè°ƒç”¨
for id in ids {
    let user = client.get_user(id).await?;
}

// GOOD: æ‰¹é‡è°ƒç”¨
let users = client.batch_get_users(ids).await?;
```

### 3. Streaming for Large Results
```rust
// BAD: ä¸€æ¬¡è¿”å›å…¨éƒ¨æ•°æ®
rpc GetPosts(Request) returns (PostList);

// GOOD: æµå¼è¿”å›
rpc GetPosts(Request) returns (stream Post);
```

---

## ğŸ“Š Monitoring Checklist

### å¿…é¡»ç›‘æ§çš„æŒ‡æ ‡

#### 1. Request Latency (è¯·æ±‚å»¶è¿Ÿ)
```promql
# P50/P95/P99
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

#### 2. Database Pool Utilization (è¿æ¥æ± åˆ©ç”¨ç‡)
```promql
db_pool_connections_active / db_pool_connections_max * 100
```

#### 3. Cache Hit Rate (ç¼“å­˜å‘½ä¸­ç‡)
```promql
sum(rate(cache_operations_total{result="hit"}[5m])) /
sum(rate(cache_operations_total{operation="get"}[5m])) * 100
```

#### 4. Error Rate (é”™è¯¯ç‡)
```promql
sum(rate(http_requests_total{status=~"5.."}[5m])) /
sum(rate(http_requests_total[5m])) * 100
```

#### 5. gRPC Latency per Service
```promql
histogram_quantile(0.95, rate(grpc_request_duration_seconds_bucket[5m]))
```

### å‘Šè­¦é˜ˆå€¼
| æŒ‡æ ‡ | è­¦å‘Š | ä¸¥é‡ |
|------|------|------|
| P95 å»¶è¿Ÿ | > 500ms | > 1s |
| è¿æ¥æ± åˆ©ç”¨ç‡ | > 75% | > 85% |
| ç¼“å­˜å‘½ä¸­ç‡ | < 60% | < 40% |
| é”™è¯¯ç‡ | > 1% | > 5% |
| CPU ä½¿ç”¨ç‡ | > 70% | > 85% |

---

## ğŸ¯ Performance Testing Commands

### Artillery åŸºå‡†æµ‹è¯•
```bash
# Feed ç”Ÿæˆå‹æµ‹
artillery run load-test/feed-load-test.yml

# ç”Ÿæˆ HTML æŠ¥å‘Š
artillery report results.json --output report.html

# å¿«é€Ÿå‹æµ‹ (å‘½ä»¤è¡Œ)
artillery quick --duration 60 --rate 100 http://localhost:8080/graphql
```

### k6 å‹æµ‹
```bash
# åŸºæœ¬å‹æµ‹
k6 run --vus 100 --duration 60s load-test/script.js

# é˜¶æ¢¯å¼åŠ å‹
k6 run --stages '5s:10,10s:20,30s:50,10s:0' script.js
```

### Database æ…¢æŸ¥è¯¢åˆ†æ
```sql
-- å¯ç”¨ pg_stat_statements
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- æŸ¥çœ‹æœ€æ…¢æŸ¥è¯¢ (Top 10)
SELECT
    query,
    calls,
    mean_exec_time,
    max_exec_time,
    stddev_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- é‡ç½®ç»Ÿè®¡
SELECT pg_stat_statements_reset();
```

---

## ğŸ”§ Quick Fixes (30åˆ†é’Ÿå†…å®æ–½)

### 1. å¯ç”¨æŸ¥è¯¢ç¼“å­˜
```rust
// åœ¨ resolver ä¸­åŒ…è£…ç¼“å­˜
async fn get_user(&self, ctx: &Context, id: ID) -> Result<User> {
    let cache = ctx.data::<Cache>()?;
    let key = format!("user:{}", id);

    if let Some(user) = cache.get(&key).await? {
        return Ok(user);
    }

    let user = self.fetch_user(id).await?;
    cache.set(&key, &user, 600).await?;
    Ok(user)
}
```

### 2. æ·»åŠ æ•°æ®åº“ç´¢å¼•
```sql
-- å¤åˆç´¢å¼• (æœ€å¸¸æŸ¥è¯¢çš„åˆ—)
CREATE INDEX CONCURRENTLY idx_posts_user_created
ON posts(user_id, created_at DESC);

-- è¦†ç›–ç´¢å¼• (é¿å…å›è¡¨)
CREATE INDEX CONCURRENTLY idx_posts_covering
ON posts(user_id) INCLUDE (id, content, created_at);
```

### 3. é…ç½®è¿æ¥æ± è¶…æ—¶
```rust
// åœ¨ db-pool é…ç½®ä¸­æ·»åŠ 
DbConfig {
    acquire_timeout_secs: 10,
    idle_timeout_secs: 600,
    max_lifetime_secs: 1800,
    ..Default::default()
}
```

---

## ğŸ“š Performance Checklist

### Pre-Deployment
- [ ] âœ… æ‰€æœ‰æŸ¥è¯¢æœ‰ç´¢å¼•æ”¯æŒ
- [ ] âœ… è¿æ¥æ± æœ‰è¶…æ—¶é…ç½®
- [ ] âœ… çƒ­è·¯å¾„æœ‰ç¼“å­˜
- [ ] âœ… æ…¢æŸ¥è¯¢æ—¥å¿—å¯ç”¨
- [ ] âœ… ç›‘æ§æŒ‡æ ‡å®Œæ•´

### Post-Deployment
- [ ] âœ… è´Ÿè½½æµ‹è¯•é€šè¿‡ (P95 < 500ms)
- [ ] âœ… ç¼“å­˜å‘½ä¸­ç‡ > 60%
- [ ] âœ… é”™è¯¯ç‡ < 1%
- [ ] âœ… æ•°æ®åº“è¿æ¥ < 75%
- [ ] âœ… Grafana ä»ªè¡¨æ¿æ­£å¸¸

### Weekly Review
- [ ] âœ… æ£€æŸ¥æ…¢æŸ¥è¯¢æ—¥å¿—
- [ ] âœ… å®¡æŸ¥ç¼“å­˜å‘½ä¸­ç‡
- [ ] âœ… ä¼˜åŒ–ä½æ•ˆç´¢å¼•
- [ ] âœ… æ¸…ç†æœªä½¿ç”¨ç´¢å¼•
- [ ] âœ… å®¹é‡è§„åˆ’æ›´æ–°

---

## ğŸ†˜ Emergency Performance Fixes

### æ•°æ®åº“è¿æ¥è€—å°½
```bash
# ä¸´æ—¶å¢åŠ è¿æ¥æ•° (éœ€é‡å¯)
ALTER SYSTEM SET max_connections = 200;
SELECT pg_reload_conf();

# æŸ¥çœ‹å½“å‰è¿æ¥
SELECT count(*) FROM pg_stat_activity;

# æ€æ­»ç©ºé—²è¿æ¥
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE state = 'idle' AND state_change < now() - interval '10 minutes';
```

### Redis å†…å­˜çˆ†æ»¡
```bash
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
redis-cli INFO memory

# ä¸´æ—¶å¢åŠ å†…å­˜é™åˆ¶
redis-cli CONFIG SET maxmemory 2gb

# æ¸…ç†è¿‡æœŸ key
redis-cli --scan --pattern "cache:*" | xargs redis-cli DEL

# è®¾ç½® LRU æ·˜æ±°ç­–ç•¥
redis-cli CONFIG SET maxmemory-policy allkeys-lru
```

### é«˜å»¶è¿Ÿæ’æŸ¥
```bash
# 1. æ£€æŸ¥ CPU
top -H -p $(pgrep -f feed-service)

# 2. æ£€æŸ¥ç½‘ç»œ
ss -s | grep ESTAB

# 3. æ£€æŸ¥ç£ç›˜ I/O
iostat -x 1

# 4. æ£€æŸ¥æ•°æ®åº“
psql -c "SELECT * FROM pg_stat_activity WHERE state != 'idle';"

# 5. æ£€æŸ¥ gRPC å»¶è¿Ÿ
curl http://localhost:8080/metrics | grep grpc_request_duration
```

---

## ğŸ”— Related Documents

- [å®Œæ•´æ€§èƒ½å®¡è®¡æŠ¥å‘Š](./PERFORMANCE_AUDIT_REPORT.md)
- [å®æ–½æŒ‡å—](./PERFORMANCE_OPTIMIZATION_IMPLEMENTATION_GUIDE.md)
- [è´Ÿè½½æµ‹è¯•](./load-test/README.md)
- [ç›‘æ§ä»ªè¡¨æ¿](http://localhost:3000/d/nova-performance)

---

**æœ€åæ›´æ–°**: 2025-11-14
**ç»´æŠ¤è€…**: Performance Engineering Team
