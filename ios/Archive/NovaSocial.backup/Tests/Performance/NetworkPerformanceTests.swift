import XCTest
@testable import NovaSocial

/// NetworkPerformanceTests - ç½‘ç»œå±‚æ€§èƒ½å’Œå‹åŠ›æµ‹è¯•
///
/// æµ‹è¯•èŒƒå›´ï¼š
/// 1. æ‰¹é‡è¯·æ±‚æ€§èƒ½
/// 2. ç¼“å­˜æ€§èƒ½æå‡
/// 3. å¹¶å‘è¯·æ±‚ååé‡
/// 4. å†…å­˜ä½¿ç”¨å’Œæ³„æ¼
/// 5. å»é‡æ€§èƒ½
///
final class NetworkPerformanceTests: XCTestCase {

    // MARK: - Setup & Teardown

    var apiClient: APIClient!
    var repository: FeedRepository!
    var cache: CacheManager!

    override func setUp() {
        super.setUp()

        let config = URLSessionConfiguration.ephemeral
        config.protocolClasses = [MockURLProtocol.self]
        let session = URLSession(configuration: config)

        apiClient = APIClient(
            baseURL: URL(string: "https://api.test.com")!,
            session: session
        )

        cache = CacheManager()
        repository = FeedRepository(apiClient: apiClient, cacheManager: cache)

        // è®¤è¯
        let user = TestFixtures.makeUser()
        let tokens = TestFixtures.makeAuthTokens()
        AuthManager.shared.saveAuth(user: user, tokens: tokens)

        MockURLProtocol.reset()
    }

    override func tearDown() {
        AuthManager.shared.clearAuth()
        MockURLProtocol.reset()
        super.tearDown()
    }

    // MARK: - Batch Request Performance

    /// æµ‹è¯•ï¼šæ‰¹é‡é¡ºåºè¯·æ±‚æ€§èƒ½
    func testPerformance_SequentialRequests() {
        // Given: Mock å“åº”
        let mockResponse = TestFixtures.makeFeedResponse()
        try! MockURLProtocol.mockJSON(mockResponse)

        // Measure: 100ä¸ªé¡ºåºè¯·æ±‚
        measure {
            let expectation = self.expectation(description: "Sequential requests")

            Task {
                for _ in 0..<100 {
                    _ = try? await self.repository.loadFeed()
                }
                expectation.fulfill()
            }

            wait(for: [expectation], timeout: 30.0)
        }
    }

    /// æµ‹è¯•ï¼šæ‰¹é‡å¹¶å‘è¯·æ±‚æ€§èƒ½
    func testPerformance_ConcurrentRequests() {
        // Given
        let mockResponse = TestFixtures.makeFeedResponse()
        try! MockURLProtocol.mockJSON(mockResponse)

        // Measure: 100ä¸ªå¹¶å‘è¯·æ±‚
        measure {
            let expectation = self.expectation(description: "Concurrent requests")

            Task {
                await withTaskGroup(of: Void.self) { group in
                    for _ in 0..<100 {
                        group.addTask {
                            _ = try? await self.repository.loadFeed()
                        }
                    }
                }
                expectation.fulfill()
            }

            wait(for: [expectation], timeout: 30.0)
        }
    }

    // MARK: - Cache Performance Tests

    /// æµ‹è¯•ï¼šç¼“å­˜å‘½ä¸­æ€§èƒ½æå‡
    func testPerformance_CacheHitVsMiss() async throws {
        // Given: å¡«å……ç¼“å­˜
        let mockResponse = TestFixtures.makeFeedResponse()
        try MockURLProtocol.mockJSON(mockResponse)
        _ = try await repository.loadFeed()

        // Measure: ç¼“å­˜å‘½ä¸­çš„è¯»å–é€Ÿåº¦
        let cacheHitStart = Date()
        for _ in 0..<1000 {
            _ = try await repository.loadFeed() // åº”è¯¥ä»ç¼“å­˜è¯»å–
        }
        let cacheHitTime = Date().timeIntervalSince(cacheHitStart)

        // Clear cache and measure cache miss
        await cache.clear()
        MockURLProtocol.responseDelay = 0.01 // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

        let cacheMissStart = Date()
        for _ in 0..<10 { // å°‘é‡è¯·æ±‚ï¼Œå› ä¸ºæœ‰ç½‘ç»œå»¶è¿Ÿ
            _ = try? await repository.loadFeed()
        }
        let cacheMissTime = Date().timeIntervalSince(cacheMissStart)

        print("ğŸ“Š Cache hit: \(cacheHitTime)s for 1000 requests")
        print("ğŸ“Š Cache miss: \(cacheMissTime)s for 10 requests")

        // ç¼“å­˜å‘½ä¸­åº”è¯¥æ˜¾è‘—æ›´å¿«
        let hitPerRequest = cacheHitTime / 1000
        let missPerRequest = cacheMissTime / 10
        XCTAssertLessThan(hitPerRequest, missPerRequest / 10, "Cache should be at least 10x faster")
    }

    /// æµ‹è¯•ï¼šç¼“å­˜ç®¡ç†å™¨æ€§èƒ½
    func testPerformance_CacheManager() {
        let cache = CacheManager()

        measure {
            Task {
                // å†™å…¥æ€§èƒ½
                for i in 0..<1000 {
                    await cache.set("value_\(i)", forKey: "key_\(i)")
                }

                // è¯»å–æ€§èƒ½
                for i in 0..<1000 {
                    let _: String? = await cache.get(forKey: "key_\(i)")
                }
            }
        }
    }

    // MARK: - Deduplication Performance

    /// æµ‹è¯•ï¼šè¯·æ±‚å»é‡æ€§èƒ½
    func testPerformance_RequestDeduplication() {
        // Given
        let mockResponse = TestFixtures.makeFeedResponse()

        var requestCount = 0
        let lock = NSLock()

        MockURLProtocol.requestHandler = { request in
            lock.lock()
            requestCount += 1
            lock.unlock()

            Thread.sleep(forTimeInterval: 0.05) // æ¨¡æ‹Ÿå»¶è¿Ÿ

            let response = TestFixtures.makeHTTPResponse()
            let data = try! TestFixtures.makeJSONData(mockResponse)
            return (response, data)
        }

        // Measure: 100ä¸ªå¹¶å‘ç›¸åŒè¯·æ±‚çš„å»é‡æ•ˆç‡
        measure {
            requestCount = 0

            let expectation = self.expectation(description: "Deduplication")

            Task {
                await withTaskGroup(of: Void.self) { group in
                    for _ in 0..<100 {
                        group.addTask {
                            _ = try? await self.repository.loadFeed()
                        }
                    }
                }
                expectation.fulfill()
            }

            wait(for: [expectation], timeout: 10.0)

            print("ğŸ“Š Deduplication: \(requestCount) actual requests for 100 concurrent calls")
        }
    }

    // MARK: - Memory Tests

    /// æµ‹è¯•ï¼šå¤§é‡æ•°æ®çš„å†…å­˜ä½¿ç”¨
    func testMemory_LargeDataset() async throws {
        // Given: å¤§é‡å¸–å­æ•°æ®
        let largePosts = TestFixtures.makePosts(count: 1000)
        let largeResponse = TestFixtures.makeFeedResponse(posts: largePosts)

        try MockURLProtocol.mockJSON(largeResponse)

        // When: å¤šæ¬¡åŠ è½½
        for _ in 0..<10 {
            _ = try await repository.loadFeed()
        }

        // Then: åº”è¯¥ä¸ä¼šå´©æºƒæˆ–å†…å­˜æº¢å‡º
        // ä½¿ç”¨ Instruments çš„ Allocations å·¥å…·æ£€æµ‹å†…å­˜ä½¿ç”¨
    }

    /// æµ‹è¯•ï¼šç¼“å­˜çš„å†…å­˜å ç”¨
    func testMemory_CacheUsage() async {
        let cache = CacheManager()

        // When: ç¼“å­˜å¤§é‡æ•°æ®
        for i in 0..<10000 {
            let posts = TestFixtures.makePosts(count: 100)
            await cache.set(posts, forKey: "key_\(i)")
        }

        // Then: æ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼ˆé€šè¿‡ Instrumentsï¼‰
        let stats = await cache.getStats()
        print("ğŸ“Š Cache stats: \(stats.totalEntries) entries")
    }

    // MARK: - Throughput Tests

    /// æµ‹è¯•ï¼šAPI ååé‡
    func testThroughput_RequestsPerSecond() async throws {
        // Given
        let mockResponse = TestFixtures.makeFeedResponse()
        try MockURLProtocol.mockJSON(mockResponse)

        // Measure throughput
        let startTime = Date()
        let requestCount = 100

        await withTaskGroup(of: Void.self) { group in
            for _ in 0..<requestCount {
                group.addTask {
                    _ = try? await self.repository.loadFeed()
                }
            }
        }

        let duration = Date().timeIntervalSince(startTime)
        let throughput = Double(requestCount) / duration

        print("ğŸ“Š Throughput: \(throughput) requests/second")
        XCTAssertGreaterThan(throughput, 10, "Should handle at least 10 requests/second")
    }

    // MARK: - Network Delay Simulation

    /// æµ‹è¯•ï¼šä¸åŒç½‘ç»œå»¶è¿Ÿä¸‹çš„æ€§èƒ½
    func testPerformance_WithNetworkDelay() async throws {
        let delays: [TimeInterval] = [0.01, 0.05, 0.1, 0.2]

        for delay in delays {
            MockURLProtocol.responseDelay = delay

            let mockResponse = TestFixtures.makeFeedResponse()
            try MockURLProtocol.mockJSON(mockResponse)

            let start = Date()
            _ = try await repository.loadFeed()
            let duration = Date().timeIntervalSince(start)

            print("ğŸ“Š Network delay \(delay)s -> Request duration: \(duration)s")

            // éªŒè¯å»¶è¿Ÿç¬¦åˆé¢„æœŸ
            XCTAssertGreaterThanOrEqual(duration, delay, "Duration should include network delay")
        }
    }

    // MARK: - Retry Performance

    /// æµ‹è¯•ï¼šé‡è¯•æœºåˆ¶çš„æ€§èƒ½å½±å“
    func testPerformance_RetryImpact() async throws {
        // Given: å‰2æ¬¡å¤±è´¥ï¼Œç¬¬3æ¬¡æˆåŠŸ
        var attemptCount = 0
        let lock = NSLock()

        MockURLProtocol.requestHandler = { request in
            lock.lock()
            attemptCount += 1
            let count = attemptCount
            lock.unlock()

            if count < 3 {
                let response = TestFixtures.makeHTTPResponse(statusCode: 503)
                return (response, nil)
            }

            let response = TestFixtures.makeHTTPResponse()
            let data = try! TestFixtures.makeJSONData(TestFixtures.makeFeedResponse())
            return (response, data)
        }

        // Measure: é‡è¯•çš„æ—¶é—´å¼€é”€
        let start = Date()
        _ = try await repository.loadFeed()
        let duration = Date().timeIntervalSince(start)

        print("ğŸ“Š Retry impact: \(attemptCount) attempts in \(duration)s")

        // åº”è¯¥ç»è¿‡äº†æŒ‡æ•°é€€é¿å»¶è¿Ÿ
        XCTAssertGreaterThan(duration, 1.0, "Should have exponential backoff delay")
    }

    // MARK: - Concurrent User Simulation

    /// æµ‹è¯•ï¼šæ¨¡æ‹Ÿå¤šç”¨æˆ·å¹¶å‘åœºæ™¯
    func testStress_MultipleUsersConcurrent() async throws {
        // Given: æ¨¡æ‹Ÿ 50 ä¸ªç”¨æˆ·åŒæ—¶ä½¿ç”¨
        let userCount = 50
        let requestsPerUser = 10

        let mockResponse = TestFixtures.makeFeedResponse()
        try MockURLProtocol.mockJSON(mockResponse)

        // When: æ¯ä¸ªç”¨æˆ·å‘é€å¤šä¸ªè¯·æ±‚
        let start = Date()

        await withTaskGroup(of: Void.self) { group in
            for _ in 0..<userCount {
                group.addTask {
                    for _ in 0..<requestsPerUser {
                        _ = try? await self.repository.loadFeed()
                    }
                }
            }
        }

        let duration = Date().timeIntervalSince(start)
        let totalRequests = userCount * requestsPerUser

        print("ğŸ“Š Stress test: \(totalRequests) requests in \(duration)s")
        print("ğŸ“Š Throughput: \(Double(totalRequests) / duration) requests/second")

        // Should handle load without crashing
    }

    // MARK: - JSON Parsing Performance

    /// æµ‹è¯•ï¼šJSON è§£ææ€§èƒ½
    func testPerformance_JSONParsing() throws {
        // Given: å¤§é‡æ•°æ®
        let largePosts = TestFixtures.makePosts(count: 1000)
        let jsonData = try TestFixtures.makeJSONData(largePosts)

        // Measure: è§£ææ€§èƒ½
        measure {
            let decoder = JSONDecoder()
            decoder.dateDecodingStrategy = .iso8601
            _ = try? decoder.decode([Post].self, from: jsonData)
        }
    }

    // MARK: - Baseline Comparison

    /// æµ‹è¯•ï¼šå»ºç«‹æ€§èƒ½åŸºå‡†
    func testBaseline_SingleRequest() {
        let mockResponse = TestFixtures.makeFeedResponse()
        try! MockURLProtocol.mockJSON(mockResponse)

        // å»ºç«‹åŸºå‡†æ€§èƒ½
        measure {
            let expectation = self.expectation(description: "Baseline")

            Task {
                _ = try? await self.repository.loadFeed()
                expectation.fulfill()
            }

            wait(for: [expectation], timeout: 5.0)
        }

        // è¿™ä¸ªåŸºå‡†å¯ä»¥ç”¨äºæ¯”è¾ƒä¼˜åŒ–å‰åçš„æ€§èƒ½
    }
}
