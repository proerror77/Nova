import Foundation
import AVFoundation
import os.log

// MARK: - Logging
private let voiceLog = OSLog(subsystem: "com.app.icered.pro", category: "GrokVoice")

/// ä½¿ç”¨ print ç¢ºä¿ log åœ¨è¨­å‚™ä¸Šå¯è¦‹
private func voiceNSLog(_ message: String) {
    print("[GrokVoice] \(message)")
}

// MARK: - Function Call Model
struct GrokFunctionCall {
    let name: String
    let callId: String
    let arguments: [String: Any]
}

// MARK: - Grok Voice Service Delegate
protocol GrokVoiceServiceDelegate: AnyObject {
    func grokVoiceStateDidChange(_ state: GrokVoiceChatState)
    func grokVoiceDidReceiveTranscript(_ text: String, isFinal: Bool)
    func grokVoiceDidReceiveResponse(_ text: String)
    func grokVoiceAudioLevelDidChange(_ level: Float)
    func grokVoiceDidReceiveAudio(_ audioData: Data)
    /// è™•ç†å‡½æ•¸èª¿ç”¨ï¼Œè¿”å›çµæœ JSON å­—ç¬¦ä¸²
    func grokVoiceDidReceiveFunctionCall(_ call: GrokFunctionCall) async -> String?
}

// MARK: - Grok Voice Service
/// xAI Grok Voice Agent API æ•´åˆæœå‹™
/// ä½¿ç”¨å¾Œç«¯ä»£ç†ç²å– ephemeral tokenï¼Œç„¶å¾Œé€£æ¥åˆ° wss://api.x.ai/v1/realtime
@Observable
@MainActor
final class GrokVoiceService: NSObject {

    // MARK: - Singleton
    static let shared = GrokVoiceService()

    // MARK: - Properties
    private(set) var state: GrokVoiceChatState = .disconnected
    private(set) var isConnected: Bool = false
    private(set) var isMuted: Bool = false
    private(set) var isPlayingResponse: Bool = false  // é˜²æ­¢è¿´éŸ³è¿´åœˆ
    private(set) var currentTranscript: String = ""
    private(set) var aiResponse: String = ""
    private(set) var selectedVoice: GrokVoiceConfig.Voice = .ara

    weak var delegate: GrokVoiceServiceDelegate?

    // Token management
    private var currentToken: GrokVoiceConfig.VoiceTokenResponse?
    private var webSocketURL: String = GrokVoiceConfig.defaultWebSocketURL

    // WebSocket
    private var webSocketTask: URLSessionWebSocketTask?
    private var urlSession: URLSession!
    private var pingTimer: Timer?
    private var reconnectAttempts = 0

    // Audio - ä½¿ç”¨å–®ä¸€ AVAudioEngine è™•ç†è¼¸å…¥å’Œè¼¸å‡º
    // é€™å°æ–¼å›éŸ³æ¶ˆé™¤è‡³é—œé‡è¦ï¼
    private var audioEngine: AVAudioEngine?
    private var audioFormat: AVAudioFormat?
    private let audioSession = AVAudioSession.sharedInstance()
    private var inputNode: AVAudioInputNode?
    private var audioBuffer: Data = Data()
    private var isCapturingAudio = false

    // Audio playback - ä½¿ç”¨åŒä¸€å€‹ engine çš„ player node
    private var playerNode: AVAudioPlayerNode?
    private var playbackFormat: AVAudioFormat?
    private var isPlaybackSetup = false
    private var pendingAudioBuffers: Int = 0  // è¿½è¹¤å¾…æ’­æ”¾çš„éŸ³è¨Šç·©è¡å€æ•¸é‡

    // è¼¸å‡ºé ç·©è¡ - é˜²æ­¢ç¶²è·¯æŠ–å‹•å°è‡´éŸ³é »æ–·æ–·çºŒçºŒ
    private var outputBuffer: Data = Data()
    private var isPreBuffering: Bool = true
    private let preBufferThreshold: Int = 4800  // 200ms @ 24kHz (24000 * 0.2 * 2 bytes)
    private let minScheduleSize: Int = 2400     // æœ€å°æ’ç¨‹å¤§å° 100msï¼Œåˆä½µå° buffer

    // Barge-in (èªéŸ³ä¸­æ–·) support
    private var currentResponseItemId: String?  // è¿½è¹¤ç•¶å‰å›æ‡‰çš„ item ID
    private var playedAudioSamples: Int = 0     // å·²æ’­æ”¾çš„éŸ³è¨Šæ¨£æœ¬æ•¸

    // ç·šç¨‹å®‰å…¨çš„æ’­æ”¾ç‹€æ…‹æ¨™è¨˜ï¼ˆç”¨æ–¼éŸ³è¨Šç·šç¨‹è¨ªå•ï¼‰
    private let playingLock = NSLock()
    private var _isPlayingAtomic: Bool = false
    private var isPlayingAtomic: Bool {
        get {
            playingLock.lock()
            defer { playingLock.unlock() }
            return _isPlayingAtomic
        }
        set {
            playingLock.lock()
            _isPlayingAtomic = newValue
            playingLock.unlock()
        }
    }

    // MARK: - Initialization

    private override init() {
        super.init()

        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = GrokVoiceConfig.connectionTimeout
        urlSession = URLSession(configuration: config, delegate: nil, delegateQueue: .main)
    }

    // MARK: - Public Methods

    /// é–‹å§‹èªéŸ³å°è©±
    func startVoiceChat(voice: GrokVoiceConfig.Voice = .ara) {
        guard state == .disconnected || state.description.contains("éŒ¯èª¤") else {
            #if DEBUG
            print("[GrokVoice] Already connected or connecting")
            #endif
            return
        }

        selectedVoice = voice
        updateState(.connecting)

        Task {
            do {
                // Step 1: Fetch ephemeral token from backend
                voiceNSLog("ğŸ“¡ Fetching ephemeral token from backend...")
                let tokenResponse = try await GrokVoiceConfig.fetchEphemeralToken()
                self.currentToken = tokenResponse
                self.webSocketURL = tokenResponse.websocketUrl

                voiceNSLog("ğŸ”‘ Got token, WebSocket URL: \(tokenResponse.websocketUrl)")

                // Step 2: Setup audio and connect
                await setupAudioSession()
                await connect(with: tokenResponse.clientSecret.value)
            } catch {
                voiceNSLog("âŒ Failed to start voice chat: \(error.localizedDescription)")
                updateState(.error(error.localizedDescription))
            }
        }
    }

    /// çµæŸèªéŸ³å°è©±
    func endVoiceChat() {
        disconnect()
        stopAudioCapture()
        stopAudioPlayback()
        updateState(.disconnected)
        currentTranscript = ""
        aiResponse = ""
        currentToken = nil
    }

    /// åˆ‡æ›éœéŸ³
    func toggleMute() {
        isMuted.toggle()

        if isMuted {
            stopAudioCapture()
        } else if isConnected {
            startAudioCapture()
        }

        #if DEBUG
        print("[GrokVoice] Mute toggled: \(isMuted)")
        #endif
    }

    /// è¨­ç½®èªéŸ³
    func setVoice(_ voice: GrokVoiceConfig.Voice) {
        selectedVoice = voice

        // å¦‚æœå·²é€£ç·šï¼Œç™¼é€ session update
        if isConnected {
            sendSessionUpdate()
        }
    }

    /// ç™¼é€æ–‡å­—è¨Šæ¯ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ–‡å­—è¼¸å…¥ï¼‰
    func sendTextMessage(_ text: String) {
        guard isConnected else { return }

        let message: [String: Any] = [
            "type": "conversation.item.create",
            "item": [
                "type": "message",
                "role": "user",
                "content": [
                    ["type": "input_text", "text": text]
                ]
            ]
        ]

        sendJSON(message)

        // è«‹æ±‚å›æ‡‰
        let responseRequest: [String: Any] = [
            "type": "response.create",
            "response": [
                "modalities": ["text", "audio"]
            ]
        ]
        sendJSON(responseRequest)
    }

    // MARK: - WebSocket Connection

    private func connect(with token: String) async {
        guard let url = URL(string: webSocketURL) else {
            updateState(.error("ç„¡æ•ˆçš„ WebSocket URL"))
            return
        }

        var request = URLRequest(url: url)
        // Use ephemeral token instead of API key
        request.setValue("Bearer \(token)", forHTTPHeaderField: "Authorization")
        // Note: xAI uses OpenAI-compatible protocol
        request.setValue("realtime=v1", forHTTPHeaderField: "OpenAI-Beta")

        webSocketTask = urlSession.webSocketTask(with: request)
        webSocketTask?.resume()

        #if DEBUG
        print("[GrokVoice] Connecting to \(url)")
        #endif

        // é–‹å§‹æ¥æ”¶è¨Šæ¯
        receiveMessage()

        // å•Ÿå‹•å¿ƒè·³è¨ˆæ™‚å™¨
        startPingTimer()

        // æ³¨æ„ï¼šsession.update æœƒåœ¨æ”¶åˆ° session.created äº‹ä»¶å¾Œç™¼é€
        // ä¸è¦åœ¨é€™è£¡ç™¼é€ï¼Œå¦å‰‡å¯èƒ½æœƒåœ¨ session å»ºç«‹å‰ç™¼é€
    }

    private func disconnect() {
        pingTimer?.invalidate()
        pingTimer = nil

        webSocketTask?.cancel(with: .normalClosure, reason: nil)
        webSocketTask = nil
        isConnected = false
        reconnectAttempts = 0
    }

    private func reconnect() {
        guard reconnectAttempts < GrokVoiceConfig.maxReconnectAttempts else {
            updateState(.error("é‡é€£å¤±æ•—"))
            return
        }

        reconnectAttempts += 1
        updateState(.connecting)

        Task {
            try? await Task.sleep(nanoseconds: UInt64(GrokVoiceConfig.reconnectDelay * 1_000_000_000))

            // Re-fetch token and connect
            do {
                let tokenResponse = try await GrokVoiceConfig.fetchEphemeralToken()
                self.currentToken = tokenResponse
                await connect(with: tokenResponse.clientSecret.value)
            } catch {
                updateState(.error(error.localizedDescription))
            }
        }
    }

    // MARK: - WebSocket Messages

    private func receiveMessage() {
        webSocketTask?.receive { [weak self] result in
            guard let self = self else { return }

            switch result {
            case .success(let message):
                Task { @MainActor [weak self] in
                    await self?.handleMessage(message)
                    await self?.receiveMessage()
                }

            case .failure(let error):
                #if DEBUG
                print("[GrokVoice] WebSocket error: \(error)")
                #endif
                Task { @MainActor [weak self] in
                    self?.handleDisconnection(error: error)
                }
            }
        }
    }

    private func handleMessage(_ message: URLSessionWebSocketTask.Message) async {
        switch message {
        case .string(let text):
            parseServerMessage(text)
        case .data(let data):
            if let text = String(data: data, encoding: .utf8) {
                parseServerMessage(text)
            }
        @unknown default:
            break
        }
    }

    private func parseServerMessage(_ text: String) {
        guard let data = text.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let type = json["type"] as? String else {
            return
        }

        #if DEBUG
        print("[GrokVoice] Received: \(type)")
        #endif

        switch type {
        case "conversation.created":
            // æ”¶åˆ° conversation.created å¾Œç™¼é€ session.update
            handleConversationCreated(json)

        case "session.updated":
            // session é…ç½®å·²æ›´æ–°ï¼Œé–‹å§‹éŸ³è¨Šæ•ç²
            handleSessionUpdated(json)

        case "input_audio_buffer.speech_started":
            print("[GrokVoice] ğŸ¤ Speech started (server VAD), isPlaying=\(isPlayingResponse)")
            // ä¼ºæœå™¨ VAD æª¢æ¸¬åˆ°ç”¨æˆ¶èªªè©±
            // å¦‚æœ AI æ­£åœ¨æ’­æ”¾ï¼Œé€™å°±æ˜¯ barge-in ä¿¡è™Ÿï¼
            if isPlayingResponse {
                print("[GrokVoice] ğŸ›‘ BARGE-IN! Server detected user speech during AI response")
                handleUserInterruption()
            }
            updateState(.listening)

        case "input_audio_buffer.speech_stopped":
            updateState(.processing)

        case "conversation.item.input_audio_transcription.completed":
            if let transcript = json["transcript"] as? String {
                currentTranscript = transcript
                delegate?.grokVoiceDidReceiveTranscript(transcript, isFinal: true)
            }

        case "response.output_item.added":
            // è¿½è¹¤ç•¶å‰å›æ‡‰çš„ item ID (ç”¨æ–¼ barge-in ä¸­æ–·)
            if let item = json["item"] as? [String: Any],
               let itemId = item["id"] as? String {
                currentResponseItemId = itemId
                playedAudioSamples = 0
                #if DEBUG
                print("[GrokVoice] Response item started: \(itemId)")
                #endif
            }

        case "response.audio_transcript.delta":
            // xAI å¯¦éš›äº‹ä»¶åç¨± (ä¸æ˜¯ response.output_audio_transcript.delta)
            if let delta = json["delta"] as? String {
                aiResponse += delta
                delegate?.grokVoiceDidReceiveResponse(aiResponse)
            }

        case "response.audio.delta":
            // xAI å¯¦éš›äº‹ä»¶åç¨± (ä¸æ˜¯ response.output_audio.delta)
            // ä¿æŒéº¥å…‹é¢¨é‹è¡Œä»¥æ”¯æ´ barge-in (èªéŸ³ä¸­æ–·)
            // iOS .voiceChat æ¨¡å¼æä¾›ç¡¬é«”ç´šå›éŸ³æ¶ˆé™¤
            if !isPlayingResponse {
                isPlayingResponse = true
                isPlayingAtomic = true  // åŒæ­¥è¨­ç½®ç·šç¨‹å®‰å…¨è®Šé‡
                print("[GrokVoice] ğŸ”Š AI response started")
            }
            if let deltaBase64 = json["delta"] as? String,
               let audioData = Data(base64Encoded: deltaBase64) {
                handleAudioDelta(audioData)
            }
            updateState(.responding)

        case "response.audio.done":
            // éŸ³è¨Šæ’­æ”¾å®Œæˆ
            break

        case "response.function_call_arguments.done":
            // è™•ç†å‡½æ•¸èª¿ç”¨
            handleFunctionCall(json)

        case "response.done":
            voiceNSLog("ğŸ“¨ response.done received")
            handleResponseDone(json)

        case "error":
            if let error = json["error"] as? [String: Any],
               let message = error["message"] as? String {
                updateState(.error(message))
            }

        default:
            break
        }
    }

    private func handleConversationCreated(_ json: [String: Any]) {
        #if DEBUG
        if let conversation = json["conversation"] as? [String: Any],
           let id = conversation["id"] as? String {
            print("[GrokVoice] Conversation created: \(id)")
        }
        #endif

        // æ”¶åˆ° conversation.created å¾Œï¼Œç™¼é€ session.update é…ç½®
        sendSessionUpdate()
    }

    private func handleSessionUpdated(_ json: [String: Any]) {
        isConnected = true
        reconnectAttempts = 0
        updateState(.connected)

        voiceNSLog("âœ… Session updated successfully")
        if let session = json["session"] as? [String: Any],
           let voice = session["voice"] as? String {
            voiceNSLog("ğŸ™ï¸ Voice: \(voice)")
        }

        // Session é…ç½®å®Œæˆå¾Œï¼Œé–‹å§‹éŸ³è¨Šæ•ç²
        if !isMuted {
            startAudioCapture()
            voiceNSLog("ğŸ¤ Audio capture started")
        }
    }

    private func handleResponseDone(_ json: [String: Any]) {
        if let response = json["response"] as? [String: Any],
           let status = response["status"] as? String {
            voiceNSLog("âœ… Response done: status=\(status), pendingBuffers=\(pendingAudioBuffers)")

            if status == "completed" || status == "cancelled" {
                // åˆ·æ–°ä»»ä½•å‰©é¤˜çš„ç·©è¡éŸ³é »ï¼ˆç¢ºä¿æœ€å¾Œçš„éŸ³é »ä¸æœƒä¸Ÿå¤±ï¼‰
                if !outputBuffer.isEmpty {
                    voiceNSLog("ğŸµ Flushing remaining \(outputBuffer.count) bytes of audio")
                    scheduleBufferedAudio()
                }

                // é‡ç½®é ç·©è¡ç‹€æ…‹ï¼Œç‚ºä¸‹ä¸€å€‹å›æ‡‰åšæº–å‚™
                isPreBuffering = true

                // æ¸…ç©ºå›æ‡‰ï¼Œæº–å‚™ä¸‹ä¸€è¼ª
                aiResponse = ""
                currentResponseItemId = nil
                updateState(.connected)

                // æ¨™è¨˜å›æ‡‰å·²å®Œæˆ
                isPlayingResponse = false
                isPlayingAtomic = false  // åŒæ­¥è¨­ç½®ç·šç¨‹å®‰å…¨è®Šé‡
                print("[GrokVoice] ğŸ”„ Response done, ready for next input")

                // å¦‚æœæ²’æœ‰å¾…æ’­æ”¾çš„éŸ³è¨Šç·©è¡å€ï¼Œç«‹å³æ¢å¾©éº¥å…‹é¢¨
                // å¦å‰‡ç­‰å¾…éŸ³è¨Šæ’­æ”¾å®Œæˆå¾Œç”± scheduleAudioBuffer çš„å®Œæˆè™•ç†å™¨æ¢å¾©
                if pendingAudioBuffers == 0 {
                    resumeMicrophoneAfterPlayback()
                }
                // å¦‚æœé‚„æœ‰å¾…æ’­æ”¾çš„ç·©è¡å€ï¼ŒscheduleAudioBuffer çš„å®Œæˆè™•ç†å™¨æœƒè™•ç†
            } else {
                voiceNSLog("âš ï¸ Response done with unexpected status: \(status)")
            }
        } else {
            voiceNSLog("âš ï¸ Response done but couldn't parse response/status")
        }
    }

    // MARK: - Barge-in (èªéŸ³ä¸­æ–·)

    /// è™•ç†ç”¨æˆ¶ä¸­æ–· AI å›æ‡‰
    private func handleUserInterruption() {
        print("[GrokVoice] ğŸ›‘ User interruption! Cancelling response...")

        // 1. ç«‹å³åœæ­¢æœ¬åœ°éŸ³è¨Šæ’­æ”¾
        clearLocalAudioPlayback()

        // 2. ç™¼é€ response.cancel åˆ°ä¼ºæœå™¨åœæ­¢ç”Ÿæˆ
        sendResponseCancel()

        // 3. å¦‚æœæœ‰ item IDï¼Œç™¼é€ truncate åŒæ­¥å°è©±ç‹€æ…‹
        if let itemId = currentResponseItemId, playedAudioSamples > 0 {
            let audioEndMs = calculatePlayedAudioMs()
            print("[GrokVoice] ğŸ“ Truncating at \(audioEndMs) ms")
            sendConversationItemTruncate(itemId: itemId, audioEndMs: audioEndMs)
        }

        // 4. é‡ç½®ç‹€æ…‹
        isPlayingResponse = false
        isPlayingAtomic = false  // åŒæ­¥è¨­ç½®ç·šç¨‹å®‰å…¨è®Šé‡
        aiResponse = ""
        currentResponseItemId = nil

        print("[GrokVoice] âœ… Interruption handled, ready for new input")
    }

    /// æ¸…ç©ºæœ¬åœ°éŸ³è¨Šæ’­æ”¾ç·©è¡å€
    private func clearLocalAudioPlayback() {
        // åœæ­¢ä¸¦é‡ç½® player node
        playerNode?.stop()
        pendingAudioBuffers = 0

        // é‡ç½®é ç·©è¡ç‹€æ…‹ï¼Œç‚ºä¸‹ä¸€å€‹å›æ‡‰åšæº–å‚™
        outputBuffer = Data()
        isPreBuffering = true

        // é‡æ–°é–‹å§‹ player ä»¥æº–å‚™æ–°çš„éŸ³è¨Š
        playerNode?.play()

        voiceNSLog("ğŸ”„ Local audio playback cleared for barge-in")
    }

    /// ç™¼é€ response.cancel äº‹ä»¶
    private func sendResponseCancel() {
        let cancelEvent: [String: Any] = [
            "type": "response.cancel"
        ]
        sendJSON(cancelEvent)

        #if DEBUG
        print("[GrokVoice] Sent response.cancel")
        #endif
    }

    /// ç™¼é€ conversation.item.truncate äº‹ä»¶
    private func sendConversationItemTruncate(itemId: String, audioEndMs: Int) {
        let truncateEvent: [String: Any] = [
            "type": "conversation.item.truncate",
            "item_id": itemId,
            "content_index": 0,
            "audio_end_ms": audioEndMs
        ]
        sendJSON(truncateEvent)

        #if DEBUG
        print("[GrokVoice] Sent conversation.item.truncate: itemId=\(itemId), audioEndMs=\(audioEndMs)")
        #endif
    }

    /// è¨ˆç®—å·²æ’­æ”¾çš„éŸ³è¨Šæ¯«ç§’æ•¸
    private func calculatePlayedAudioMs() -> Int {
        // 24kHz æ¡æ¨£ç‡ï¼Œæ¯å€‹æ¨£æœ¬ = 1/24000 ç§’
        let sampleRate = GrokVoiceConfig.defaultSampleRate.rawValue
        let playedMs = (playedAudioSamples * 1000) / sampleRate
        return playedMs
    }

    private func handleFunctionCall(_ json: [String: Any]) {
        guard let name = json["name"] as? String,
              let callId = json["call_id"] as? String,
              let argumentsString = json["arguments"] as? String else {
            #if DEBUG
            print("[GrokVoice] Invalid function call event")
            #endif
            return
        }

        #if DEBUG
        print("[GrokVoice] Function called: \(name) with call_id: \(callId)")
        #endif

        // è§£æåƒæ•¸ JSON
        var arguments: [String: Any] = [:]
        if let data = argumentsString.data(using: .utf8),
           let parsed = try? JSONSerialization.jsonObject(with: data) as? [String: Any] {
            arguments = parsed
        }

        let functionCall = GrokFunctionCall(name: name, callId: callId, arguments: arguments)

        // èª¿ç”¨ delegate åŸ·è¡Œå‡½æ•¸
        Task {
            if let result = await delegate?.grokVoiceDidReceiveFunctionCall(functionCall) {
                // ç™¼é€å‡½æ•¸çµæœ
                sendFunctionResult(callId: callId, output: result)
            } else {
                // æ²’æœ‰çµæœï¼Œç™¼é€ç©ºçµæœ
                sendFunctionResult(callId: callId, output: "{\"error\": \"Function not implemented\"}")
            }
        }
    }

    /// ç™¼é€å‡½æ•¸åŸ·è¡Œçµæœ
    private func sendFunctionResult(callId: String, output: String) {
        // ç™¼é€ conversation.item.create å¸¶å‡½æ•¸è¼¸å‡º
        let createItem: [String: Any] = [
            "type": "conversation.item.create",
            "item": [
                "type": "function_call_output",
                "call_id": callId,
                "output": output
            ]
        ]

        sendJSON(createItem)

        #if DEBUG
        print("[GrokVoice] Sent function result for call_id: \(callId)")
        #endif

        // ç™¼é€ response.create è®“ agent ç¹¼çºŒ
        let responseCreate: [String: Any] = [
            "type": "response.create"
        ]
        sendJSON(responseCreate)

        #if DEBUG
        print("[GrokVoice] Sent response.create to continue")
        #endif
    }

    private func handleDisconnection(error: Error) {
        isConnected = false

        if state != .disconnected {
            reconnect()
        }
    }

    // MARK: - Send Messages

    private func sendJSON(_ object: [String: Any]) {
        guard let data = try? JSONSerialization.data(withJSONObject: object),
              let text = String(data: data, encoding: .utf8) else {
            return
        }

        webSocketTask?.send(.string(text)) { error in
            if let error = error {
                #if DEBUG
                print("[GrokVoice] Send error: \(error)")
                #endif
            }
        }
    }

    private func sendSessionUpdate() {
        let config = GrokVoiceConfig.aliceSessionConfig(voice: selectedVoice)
        sendJSON(config)
    }

    // è¿½è¹¤éŸ³è¨Šç™¼é€ç‹€æ…‹
    private var lastAudioSentTime: Date = .distantPast
    private var audioSendCount: Int = 0

    private func sendAudioBuffer(_ audioData: Data) {
        let base64Audio = audioData.base64EncodedString()
        let message: [String: Any] = [
            "type": "input_audio_buffer.append",
            "audio": base64Audio
        ]
        sendJSON(message)

        // æ¯ 50 æ¬¡ç™¼é€è¨˜éŒ„ä¸€æ¬¡ï¼Œé¿å…æ—¥èªŒéå¤š
        audioSendCount += 1
        if audioSendCount % 50 == 1 {
            voiceNSLog("ğŸ“¤ Sending audio #\(audioSendCount), isPlaying=\(isPlayingResponse)")
        }
    }

    // MARK: - Ping/Pong

    private func startPingTimer() {
        pingTimer?.invalidate()
        pingTimer = Timer.scheduledTimer(withTimeInterval: GrokVoiceConfig.heartbeatInterval, repeats: true) { [weak self] _ in
            Task { @MainActor [weak self] in
                self?.webSocketTask?.sendPing { error in
                    if let error = error {
                        #if DEBUG
                        print("[GrokVoice] Ping error: \(error)")
                        #endif
                    }
                }
            }
        }
    }

    // MARK: - Audio Session

    private func setupAudioSession() async {
        do {
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .allowBluetoothHFP])
            try audioSession.setActive(true)

            #if DEBUG
            print("[GrokVoice] Audio session configured")
            #endif
        } catch {
            #if DEBUG
            print("[GrokVoice] Audio session error: \(error)")
            #endif
            updateState(.error("ç„¡æ³•é…ç½®éŸ³è¨Š: \(error.localizedDescription)"))
        }
    }

    // MARK: - Audio Capture

    private func startAudioCapture() {
        guard !isCapturingAudio else { return }

        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else { return }

        inputNode = audioEngine.inputNode
        guard let inputNode = inputNode else { return }

        // å•Ÿç”¨èªéŸ³è™•ç†é€²è¡Œå›éŸ³æ¶ˆé™¤
        // é€™æ˜¯ iOS ä¸Šå¯¦ç¾ barge-in çš„é—œéµï¼
        do {
            try inputNode.setVoiceProcessingEnabled(true)
            voiceNSLog("ğŸ”Š Voice processing enabled on input node (echo cancellation)")
        } catch {
            voiceNSLog("âš ï¸ Failed to enable voice processing on input: \(error.localizedDescription)")
        }

        // åŒæ™‚è¨­ç½®æ’­æ”¾ç¯€é»åœ¨åŒä¸€å€‹ engine ä¸Š
        // é€™æ¨£å›éŸ³æ¶ˆé™¤å¯ä»¥æ­£ç¢ºå·¥ä½œ
        setupPlayerNodeOnEngine(audioEngine)

        // ç›®æ¨™æ ¼å¼: 24kHz PCM16 mono
        let targetSampleRate = Double(GrokVoiceConfig.defaultSampleRate.rawValue)
        guard let targetFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: targetSampleRate,
            channels: 1,
            interleaved: true
        ) else { return }

        audioFormat = targetFormat

        // ç²å–è¼¸å…¥ç¯€é»çš„åŸç”Ÿæ ¼å¼
        let inputFormat = inputNode.outputFormat(forBus: 0)

        voiceNSLog("ğŸ“¥ Input format: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount) channels")
        voiceNSLog("ğŸ¯ Target format: \(targetSampleRate)Hz, 1 channel, PCM16")

        // å‰µå»ºæ ¼å¼è½‰æ›å™¨
        guard let converter = AVAudioConverter(from: inputFormat, to: targetFormat) else {
            voiceNSLog("âŒ Failed to create audio converter")
            return
        }

        // å®‰è£ tap ä¾†æ•ç²éŸ³è¨Š
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: inputFormat) { [weak self] buffer, _ in
            self?.processAudioBuffer(buffer, converter: converter, targetFormat: targetFormat)
        }

        do {
            try audioEngine.start()
            isCapturingAudio = true
            playerNode?.play()  // ç¢ºä¿ player ä¹Ÿé–‹å§‹
            voiceNSLog("âœ… Audio engine started (capture + playback on same engine)")
        } catch {
            voiceNSLog("âŒ Failed to start audio engine: \(error.localizedDescription)")
        }
    }

    /// åœ¨åŒä¸€å€‹ engine ä¸Šè¨­ç½® player node
    private func setupPlayerNodeOnEngine(_ engine: AVAudioEngine) {
        // å‰µå»ºä¸¦é™„åŠ  player node
        playerNode = AVAudioPlayerNode()
        guard let player = playerNode else { return }

        // 24kHz PCM16 mono - èˆ‡ xAI API è¼¸å‡ºæ ¼å¼åŒ¹é…
        let sampleRate = Double(GrokVoiceConfig.defaultSampleRate.rawValue)
        playbackFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: sampleRate,
            channels: 1,
            interleaved: true
        )

        guard let format = playbackFormat else { return }

        engine.attach(player)
        engine.connect(player, to: engine.mainMixerNode, format: format)

        // å•Ÿç”¨è¼¸å‡ºç¯€é»çš„èªéŸ³è™•ç†ä»¥é…åˆå›éŸ³æ¶ˆé™¤
        do {
            try engine.outputNode.setVoiceProcessingEnabled(true)
            voiceNSLog("ğŸ”Š Voice processing enabled on output node (echo cancellation)")
        } catch {
            voiceNSLog("âš ï¸ Failed to enable voice processing on output: \(error.localizedDescription)")
        }

        isPlaybackSetup = true
        voiceNSLog("ğŸµ Player node attached to unified engine")
    }

    private func stopAudioCapture() {
        guard isCapturingAudio else { return }

        inputNode?.removeTap(onBus: 0)
        playerNode?.stop()  // åœæ­¢æ’­æ”¾ç¯€é»
        audioEngine?.stop()
        audioEngine = nil
        inputNode = nil
        playerNode = nil
        isCapturingAudio = false
        isPlaybackSetup = false

        voiceNSLog("ğŸ›‘ Audio engine stopped (capture + playback)")
    }

    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer, converter: AVAudioConverter, targetFormat: AVAudioFormat) {
        // ä½¿ç”¨ç·šç¨‹å®‰å…¨çš„æ–¹å¼æª¢æŸ¥é€£æ¥å’ŒéœéŸ³ç‹€æ…‹
        let connected = isConnected
        let muted = isMuted
        guard connected, !muted else { return }

        // è¨ˆç®—è½‰æ›å¾Œçš„å¹€æ•¸
        let ratio = targetFormat.sampleRate / buffer.format.sampleRate
        let outputFrameCapacity = AVAudioFrameCount(Double(buffer.frameLength) * ratio)

        guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: outputFrameCapacity) else {
            return
        }

        // åŸ·è¡Œæ ¼å¼è½‰æ›
        var error: NSError?
        let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }

        converter.convert(to: outputBuffer, error: &error, withInputFrom: inputBlock)

        if let error = error {
            #if DEBUG
            print("[GrokVoice] Audio conversion error: \(error)")
            #endif
            return
        }

        // ç²å–è½‰æ›å¾Œçš„ PCM16 æ•¸æ“š
        guard let channelData = outputBuffer.int16ChannelData else { return }

        let frameCount = Int(outputBuffer.frameLength)
        let data = Data(bytes: channelData[0], count: frameCount * 2)

        // è¨ˆç®—éŸ³é‡ç´šåˆ¥
        var sum: Float = 0
        for i in 0..<frameCount {
            let sample = Float(channelData[0][i]) / Float(Int16.max)
            sum += sample * sample
        }
        let rms = sqrt(sum / Float(frameCount))
        let level = min(1.0, rms * 3)  // æ”¾å¤§ä»¥ä¾¿æ›´å¥½åœ°å¯è¦–åŒ–

        Task { @MainActor in
            self.delegate?.grokVoiceAudioLevelDidChange(level)
        }

        // é—œéµæ”¹å‹•ï¼šå§‹çµ‚ç™¼é€éŸ³è¨Šåˆ°ä¼ºæœå™¨ï¼
        // ä¼ºæœå™¨ VAD æœƒè™•ç†å›éŸ³æ¶ˆé™¤å’ŒèªéŸ³æª¢æ¸¬
        // ç•¶ç”¨æˆ¶åœ¨ AI æ’­æ”¾æ™‚èªªè©±ï¼Œä¼ºæœå™¨æœƒç™¼é€ input_audio_buffer.speech_started
        // æˆ‘å€‘åœ¨è©²äº‹ä»¶è™•ç†å™¨ä¸­åŸ·è¡Œ barge-in
        sendAudioBuffer(data)
    }

    // MARK: - Audio Playback (Streaming with AVAudioEngine)

    /// ç¢ºä¿æ’­æ”¾è¨­ç½®å·²å®Œæˆï¼ˆç¾åœ¨ç”± startAudioCapture çµ±ä¸€è™•ç†ï¼‰
    private func ensurePlaybackReady() {
        // æ’­æ”¾è¨­ç½®ç¾åœ¨åœ¨ startAudioCapture ä¸­èˆ‡æ•ç²ä¸€èµ·åˆå§‹åŒ–
        // é€™ç¢ºä¿è¼¸å…¥å’Œè¼¸å‡ºåœ¨åŒä¸€å€‹ engine ä¸Šï¼Œä»¥ä¾¿å›éŸ³æ¶ˆé™¤æ­£å¸¸å·¥ä½œ
        guard isPlaybackSetup, playerNode != nil else {
            voiceNSLog("âš ï¸ Playback not ready - audio capture may not have started")
            return
        }
    }

    private func handleAudioDelta(_ audioData: Data) {
        // ç¢ºä¿æ’­æ”¾å·²æº–å‚™å¥½ï¼ˆæ‡‰è©²åœ¨ startAudioCapture ä¸­å·²è¨­ç½®ï¼‰
        if !isPlaybackSetup {
            ensurePlaybackReady()
        }

        // ç´¯ç©éŸ³é »æ•¸æ“šåˆ°è¼¸å‡ºç·©è¡å€
        outputBuffer.append(audioData)

        if isPreBuffering {
            // é ç·©è¡éšæ®µï¼šç´¯ç©è¶³å¤ æ•¸æ“šå¾Œæ‰é–‹å§‹æ’­æ”¾ï¼Œé˜²æ­¢ç¶²è·¯æŠ–å‹•
            if outputBuffer.count >= preBufferThreshold {
                isPreBuffering = false
                voiceNSLog("ğŸµ Pre-buffer complete (\(outputBuffer.count) bytes), starting playback")
                scheduleBufferedAudio()
            }
        } else {
            // å·²é–‹å§‹æ’­æ”¾ï¼šç•¶ç´¯ç©é”åˆ°æœ€å°æ’ç¨‹å¤§å°æ™‚æ’ç¨‹
            if outputBuffer.count >= minScheduleSize {
                scheduleBufferedAudio()
            }
        }

        delegate?.grokVoiceDidReceiveAudio(audioData)
    }

    /// æ’ç¨‹ç´¯ç©çš„éŸ³é »ç·©è¡å€
    private func scheduleBufferedAudio() {
        guard !outputBuffer.isEmpty else { return }

        // å–å‡ºæ‰€æœ‰ç´¯ç©çš„æ•¸æ“š
        let dataToSchedule = outputBuffer
        outputBuffer = Data()

        // æ’ç¨‹æ’­æ”¾
        scheduleAudioBuffer(dataToSchedule)
    }

    private func scheduleAudioBuffer(_ data: Data) {
        guard let format = playbackFormat,
              let player = playerNode,
              player.engine != nil else { return }

        // è¨ˆç®—å¹€æ•¸: data.count / 2 (å› ç‚ºæ˜¯ 16-bit = 2 bytes per sample)
        let frameCount = AVAudioFrameCount(data.count / 2)
        let sampleCount = Int(frameCount)

        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
            return
        }

        buffer.frameLength = frameCount

        // è¤‡è£½ PCM16 æ•¸æ“šåˆ° buffer
        data.withUnsafeBytes { rawBuffer in
            if let src = rawBuffer.baseAddress {
                memcpy(buffer.int16ChannelData?[0], src, data.count)
            }
        }

        // å¢åŠ å¾…æ’­æ”¾ç·©è¡å€è¨ˆæ•¸
        pendingAudioBuffers += 1

        // æ’ç¨‹åˆ° player nodeï¼Œä¸¦è¿½è¹¤æ’­æ”¾å®Œæˆ
        player.scheduleBuffer(buffer) { [weak self] in
            DispatchQueue.main.async {
                guard let self = self else { return }
                self.pendingAudioBuffers -= 1

                // è¿½è¹¤å·²æ’­æ”¾çš„éŸ³è¨Šæ¨£æœ¬æ•¸ (ç”¨æ–¼ barge-in truncate)
                self.playedAudioSamples += sampleCount

                // ç•¶æ‰€æœ‰ç·©è¡å€æ’­æ”¾å®Œç•¢ä¸”å›æ‡‰å·²å®Œæˆï¼Œæ¢å¾©éº¥å…‹é¢¨
                if self.pendingAudioBuffers == 0 && !self.isPlayingResponse {
                    self.resumeMicrophoneAfterPlayback()
                }
            }
        }
    }

    private func resumeMicrophoneAfterPlayback() {
        guard !isMuted, isConnected else { return }

        // éº¥å…‹é¢¨ç¾åœ¨ä¿æŒé‹è¡Œï¼ˆæ”¯æ´ barge-inï¼‰ï¼Œåªéœ€é‡ç½®æ’­æ”¾ç‹€æ…‹
        voiceNSLog("ğŸ¤ Playback complete, mic already running for barge-in")

        // ç¢ºä¿éŸ³è¨Šæ•ç²ä»åœ¨é‹è¡Œï¼ˆä»¥é˜²è¬ä¸€ï¼‰
        if !isCapturingAudio {
            startAudioCapture()
            voiceNSLog("ğŸ¤ Restarted mic (was stopped)")
        }
    }

    private func stopAudioPlayback() {
        playerNode?.stop()
        // ä¸éœ€è¦åœæ­¢ engineï¼Œå› ç‚ºå®ƒèˆ‡ capture å…±ç”¨
        // audioEngine æœƒåœ¨ stopAudioCapture ä¸­åœæ­¢
        playerNode = nil
        isPlaybackSetup = false
        pendingAudioBuffers = 0

        // é‡ç½®é ç·©è¡ç‹€æ…‹
        outputBuffer = Data()
        isPreBuffering = true

        voiceNSLog("ğŸ”‡ Playback stopped")
    }

    // MARK: - State Management

    private func updateState(_ newState: GrokVoiceChatState) {
        state = newState
        isConnected = newState.isActive
        delegate?.grokVoiceStateDidChange(newState)
    }
}
