# Nova æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–åˆ†ææŠ¥å‘Š

**åˆ†ææ—¥æœŸ**: 2025-11-24
**åˆ†æèŒƒå›´**: Nova å¾®æœåŠ¡åç«¯æ•°æ®åº“æ¶æ„
**ç›®æ ‡**: è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶æä¾›ä¼˜åŒ–å»ºè®®

---

## æ‰§è¡Œæ‘˜è¦

Nova çš„æ•°æ®åº“æ¶æ„åŒ…æ‹¬ PostgreSQLã€Neo4jã€ClickHouse å’Œ Redis çš„æ··åˆå †æ ˆã€‚æ•´ä½“æ¶æ„è®¾è®¡åˆç†ï¼Œä½†å­˜åœ¨ä»¥ä¸‹ä¼˜åŒ–æœºä¼šï¼š

### å…³é”®å‘ç°

| é—®é¢˜ç±»åˆ« | ä¸¥é‡æ€§ | å½±å“èŒƒå›´ | ä¿®å¤éš¾åº¦ |
|---------|--------|---------|---------|
| ç¼ºå°‘å¤åˆç´¢å¼• | ğŸ”´ é«˜ | Feed/æœç´¢æŸ¥è¯¢ | ä½ |
| è¿æ¥æ± é…ç½®ä¿å®ˆ | ğŸŸ¡ ä¸­ | é«˜å¹¶å‘åœºæ™¯ | ä½ |
| N+1 é£é™©ï¼ˆGraphQLï¼‰ | ğŸŸ¡ ä¸­ | GraphQL API | ä¸­ |
| åˆ†æè¡¨ç¼ºåˆ†åŒº | ğŸŸ¡ ä¸­ | ClickHouse å†·æ•°æ® | é«˜ |
| ç¼“å­˜ç­–ç•¥å•ä¸€ | ğŸŸ¡ ä¸­ | è®¡æ•°å™¨æ“ä½œ | ä¸­ |

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šPostgreSQL æŸ¥è¯¢åˆ†æ

### 1.1 æ•°æ®åº“æŸ¥è¯¢ç°çŠ¶è¯„ä¼°

**âœ… å·²å®ç°çš„è‰¯å¥½å®è·µ**:

1. **å‚æ•°åŒ–æŸ¥è¯¢** (`sqlx::query!`, `sqlx::query_as`)
   - æ‰€æœ‰æŸ¥è¯¢ä½¿ç”¨ç»‘å®šå‚æ•°ï¼Œæ—  SQL æ³¨å…¥é£é™©
   - ç¼–è¯‘æ—¶æ£€æŸ¥ï¼ˆsqlx macroï¼‰

2. **è½¯åˆ é™¤ç­–ç•¥**
   - Posts ä½¿ç”¨ `soft_delete IS NULL` è¿‡æ»¤
   - ä¿ç•™å®¡è®¡æ—¥å¿—å’Œæ•°æ®ä¸€è‡´æ€§

3. **ä¹è§‚é”å®šè®¾è®¡**
   - Likes/Comments ä½¿ç”¨ UPSERTï¼ˆON CONFLICTï¼‰
   - åŸå­åŒ–æ“ä½œï¼Œæ— ç«æ€æ¡ä»¶

4. **äº‹åŠ¡éš”ç¦»**
   - å…³é”®æ“ä½œä½¿ç”¨æ•°æ®åº“çº§åˆ«çš„ UNIQUE çº¦æŸ
   - ä¾‹ï¼š`CONSTRAINT unique_like_per_user_per_post UNIQUE (post_id, user_id)`

### 1.2 N+1 æŸ¥è¯¢é—®é¢˜åˆ†æ

**å‘ç°çš„æ½œåœ¨ N+1 åœºæ™¯**:

#### åœºæ™¯ 1: GraphQL åŠ è½½å™¨å®ç°ï¼ˆä¸­ç­‰é£é™©ï¼‰

ğŸ“‚ æ–‡ä»¶: `/graphql-gateway/src/schema/loaders.rs`

```rust
// å½“å‰å®ç°
impl Loader<String> for UserIdLoader {
    async fn load(&self, keys: &[String]) -> Result<HashMap<String, Self::Value>, Self::Error> {
        // âš ï¸ æ³¨é‡Šæ˜¾ç¤ºæ„å›¾ä½†æœªå®ç°
        // SELECT id, name FROM users WHERE id IN (keys)
        //
        // å®é™…ä»£ç åªæ˜¯æ¨¡æ‹Ÿç”Ÿæˆæ•°æ®
        let users: HashMap<String, String> = keys
            .iter()
            .map(|id| (id.clone(), format!("User {}", id)))
            .collect();
        Ok(users)
    }
}
```

**é£é™©åˆ†æ**:
- DataLoader æ¡†æ¶å·²éƒ¨ç½²ä½†**æœªè¿æ¥çœŸå®æ•°æ®åº“æŸ¥è¯¢**
- ç”Ÿäº§ç¯å¢ƒä¸­ä»å­˜åœ¨æ½œåœ¨ N+1 é£é™©
- GraphQL Post å­—æ®µçš„ `creator_id` åŠ è½½æœªä¼˜åŒ–

**å»ºè®®**:
```rust
// âœ… å®ç°çœŸå®æ‰¹é‡åŠ è½½
impl Loader<Uuid> for UserIdLoader {
    async fn load(&self, keys: &[Uuid]) -> Result<HashMap<Uuid, User>, Self::Error> {
        let users: Vec<User> = sqlx::query_as!(
            User,
            "SELECT id, name, avatar FROM users WHERE id = ANY($1)",
            &keys[..]
        )
        .fetch_all(&self.db_pool)
        .await?;

        Ok(users.into_iter().map(|u| (u.id, u)).collect())
    }
}
```

#### åœºæ™¯ 2: è¯„è®ºæ ‘åŠ è½½ï¼ˆä¸­ç­‰é£é™©ï¼‰

ğŸ“‚ æ–‡ä»¶: `/social-service/src/repository/comments.rs`

å½“å‰å®ç°ï¼š
```rust
// âœ… å•æ¡æ³¨é‡ŠæŸ¥è¯¢ä¼˜åŒ–
pub async fn get_comment(&self, comment_id: Uuid) -> Result<Option<Comment>> {
    // æŸ¥è¯¢å•æ¡æ³¨é‡Š - æœ‰ç´¢å¼•ä¿æŠ¤
}

// âš ï¸ çˆ¶æ³¨é‡ŠåŠ è½½å¯èƒ½æ˜¯ N+1
pub async fn get_comments(
    &self,
    post_id: Uuid,
    limit: i32,
    offset: i32,
) -> Result<Vec<Comment>> {
    // è·å–åˆ†é¡µæ³¨é‡Š
    // å¦‚æœå®¢æˆ·ç«¯éšåä¸ºæ¯æ¡æ³¨é‡ŠåŠ è½½ parent_commentï¼Œä¼šäº§ç”Ÿ N æ¬¡æŸ¥è¯¢
}
```

**é£é™©è¯„åˆ†**: âš ï¸ ä¸­ - ä»…åœ¨å®¢æˆ·ç«¯åŠ è½½çˆ¶æ³¨é‡Šæ—¶è§¦å‘

---

### 1.3 ç´¢å¼•è¦†ç›–ç‡åˆ†æ

#### âœ… å·²æœ‰çš„ç´¢å¼•ï¼ˆå¥½ï¼‰

**ç¤¾äº¤äº¤äº’è¡¨** (`likes`, `comments`, `shares`):
```sql
CREATE INDEX idx_likes_post_id ON likes(post_id);
CREATE INDEX idx_likes_user_id ON likes(user_id);
CREATE INDEX idx_comments_post_id ON comments(post_id) WHERE is_deleted = FALSE;
CREATE INDEX idx_comments_parent_id ON comments(parent_comment_id) WHERE parent_comment_id IS NOT NULL;
CREATE INDEX idx_shares_post_id ON shares(post_id);
CREATE INDEX idx_shares_user_id ON shares(user_id);
```

**çŠ¶æ€**: âœ… å……è¶³

#### ğŸ”´ ç¼ºå¤±çš„å¤åˆç´¢å¼•ï¼ˆå…³é”®ä¼˜åŒ–ç‚¹ï¼‰

**é—®é¢˜ 1: æ’åº/åˆ†é¡µæŸ¥è¯¢ç¼ºä¹è¦†ç›–ç´¢å¼•**

ğŸ“‚ å—å½±å“çš„æŸ¥è¯¢:
- `get_post_likes(post_id, limit, offset)` - æŒ‰ `created_at DESC` æ’åº
- `get_comments(post_id, limit, offset)` - æŒ‰ `created_at DESC` æˆ– `updated_at DESC` æ’åº

**å½“å‰æˆæœ¬åˆ†æ**:
```
æ²¡æœ‰è¦†ç›–ç´¢å¼•çš„æƒ…å†µ:
  1. Index Scan: idx_likes_post_id
  2. ä»ç£ç›˜è¯»å–æ‰€æœ‰åŒ¹é…è¡Œ
  3. æ’åº created_at DESCï¼ˆå†…å­˜æ’åºï¼‰
  4. è¿”å›å‰ limit è¡Œ

  æˆæœ¬: O(n) where n = è¯¥å¸–å­çš„æ‰€æœ‰ç‚¹èµæ•°
  å¯¹äºçƒ­é—¨å†…å®¹ï¼ˆ100k+ ç‚¹èµï¼‰: 100-500ms
```

**å»ºè®®çš„ç´¢å¼•**:
```sql
-- æ–¹æ¡ˆ A: è¦†ç›–ç´¢å¼•ï¼ˆæœ€ä¼˜ï¼‰
CREATE INDEX idx_likes_post_created_id ON likes(post_id, created_at DESC, user_id, id)
  WHERE deleted_at IS NULL;

-- æ–¹æ¡ˆ B: å¤åˆç´¢å¼• + é™åº
CREATE INDEX idx_comments_post_created ON comments(post_id, created_at DESC)
  WHERE is_deleted = FALSE;

-- æ–¹æ¡ˆ C: è¯„è®ºæ ‘å¯¼èˆª
CREATE INDEX idx_comments_parent_created ON comments(parent_comment_id, created_at DESC)
  WHERE parent_comment_id IS NOT NULL AND is_deleted = FALSE;
```

**é¢„æœŸæ€§èƒ½æ”¹è¿›**:
- çƒ­é—¨å†…å®¹ç‚¹èµåˆ†é¡µ: 500ms â†’ 50ms (10å€)
- è¯„è®ºåŠ è½½: 300ms â†’ 30ms (10å€)
- ç´¢å¼•å­˜å‚¨æˆæœ¬: ~500MB é¢å¤–å­˜å‚¨

#### ğŸ”´ ç¼ºå¤±çš„ç”¨æˆ·æ´»åŠ¨ç´¢å¼•

**é—®é¢˜**: ç”¨æˆ·å‘ç°/å…³æ³¨æ¨èç¼ºå°‘å…³é”®æŸ¥è¯¢ä¼˜åŒ–

ğŸ“‚ å—å½±å“çš„æŸ¥è¯¢:
- `find_posts_by_user(user_id, limit, offset)` - å·²æœ‰ç´¢å¼• âœ…
- ç”¨æˆ·è·Ÿè¸ªå›¾æŸ¥è¯¢ - Neo4j ä¾§ âš ï¸

**å»ºè®®**:
```sql
-- ç”¨æˆ·å…³æ³¨åº¦è®¡æ•°å¿«é€ŸæŸ¥è¯¢
CREATE INDEX idx_users_follower_count ON users(follower_count DESC)
  WHERE is_active = TRUE;

-- ç”¨æˆ·äº’åŠ¨çƒ­åº¦æ’åº
CREATE INDEX idx_users_interaction_score ON users(
  interaction_score DESC,
  created_at DESC
)
  WHERE is_active = TRUE;
```

---

### 1.4 è¿æ¥æ± é…ç½®åˆ†æ

#### å½“å‰é…ç½®è¯„ä¼°

**é…ç½®ä½ç½®** (å„æœåŠ¡):
- `social-service/src/main.rs`
- `feed-service/src/config/mod.rs`
- `user-service/src/main.rs`
- `graphql-gateway/src/config.rs`

**å‘ç°çš„é…ç½®æ¨¡å¼**:

```rust
// å…¸å‹é…ç½®
pub max_connections: u32,  // ä» DATABASE_MAX_CONNECTIONS ç¯å¢ƒå˜é‡è¯»å–

// çº¦æŸæ£€æŸ¥ï¼ˆéƒ¨åˆ†æœåŠ¡ï¼‰
if cfg.max_connections < 20 {
    cfg.max_connections = 20;  // notification-service å¼ºåˆ¶æœ€å°å€¼
}
```

**é—®é¢˜åˆ†æ**:

| æ–¹é¢ | å½“å‰çŠ¶æ€ | é£é™© | å»ºè®® |
|------|---------|------|------|
| **æœ€å¤§è¿æ¥æ•°** | ENV é©±åŠ¨ï¼Œæ— å›ºå®šå€¼ | ğŸŸ¡ å¯èƒ½è¿‡ä½/è¿‡é«˜ | 30-50ï¼ˆä¸­ç­‰è´Ÿè½½ï¼‰ |
| **ç©ºé—²è¶…æ—¶** | âŒ æœªé…ç½® | ğŸ”´ è¿æ¥æ³„æ¼ | 5-10åˆ†é’Ÿ |
| **è·å–è¶…æ—¶** | âŒ æœªé…ç½® | ğŸ”´ æ— é™ç­‰å¾… | 10ç§’ |
| **è¿æ¥è¶…æ—¶** | âŒ æœªé…ç½® | ğŸ”´ é•¿æœŸè¿æ¥å»ºç«‹ | 5ç§’ |
| **éªŒè¯æŸ¥è¯¢** | âŒ ç¼ºå¤± | ğŸŸ¡ åƒµå°¸è¿æ¥ | `SELECT 1` |

**ä»£ç ç°çŠ¶**:
```rust
// âŒ ä¸å®Œæ•´çš„é…ç½®
pub async fn create_pool(url: &str, max_connections: u32) -> Result<PgPool> {
    let pool = PgPoolOptions::new()
        .max_connections(max_connections)
        .connect(url)  // âš ï¸ ç¼ºå°‘è¶…æ—¶é…ç½®ï¼
        .await?;
    Ok(pool)
}
```

#### ğŸ”´ æ¨èçš„å®Œæ•´é…ç½®

```rust
// âœ… ç”Ÿäº§çº§åˆ«çš„è¿æ¥æ± é…ç½®
pub async fn create_pool(url: &str, max_connections: u32) -> Result<PgPool> {
    let pool = PgPoolOptions::new()
        // è¿æ¥é™åˆ¶
        .max_connections(max_connections)
        .min_connections(max_connections / 2)  // ç»´æŒé¢„çƒ­è¿æ¥

        // è¿æ¥å»ºç«‹è¶…æ—¶
        .connect_timeout(Duration::from_secs(5))

        // è·å–è¿æ¥è¶…æ—¶ï¼ˆé¿å…æ— é™ç­‰å¾…ï¼‰
        .acquire_timeout(Duration::from_secs(10))

        // ç©ºé—²è¿æ¥ç”Ÿå­˜æ—¶é—´
        .idle_timeout(Some(Duration::from_secs(600)))  // 10åˆ†é’Ÿ

        // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´ï¼ˆåˆ·æ–°è¿æ¥ï¼‰
        .max_lifetime(Some(Duration::from_secs(3600)))  // 1å°æ—¶

        // å®šæœŸéªŒè¯è¿æ¥æœ‰æ•ˆæ€§
        .test_on_checkout(true)

        .connect(url)
        .await?;

    Ok(pool)
}
```

**é…ç½®å€¼æ ¹æ®æœåŠ¡è°ƒæ•´**:

```yaml
# social-service (é«˜å†™å…¥)
max_connections: 50
min_connections: 25
acquire_timeout: 10s

# feed-service (é«˜è¯»å–)
max_connections: 40
min_connections: 20
acquire_timeout: 15s

# graphql-gateway (æ··åˆ + åˆ†å‘)
max_connections: 80
min_connections: 40
acquire_timeout: 20s

# notification-service (ä½æµé‡)
max_connections: 20
min_connections: 10
acquire_timeout: 10s
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šNeo4j æŸ¥è¯¢ä¼˜åŒ–

### 2.1 å½“å‰ Neo4j å®ç°è¯„ä¼°

ğŸ“‚ æ–‡ä»¶: `/graph-service/src/repository/graph_repository.rs`

**âœ… å·²å®ç°çš„æœ€ä½³å®è·µ**:

1. **ä¹è§‚é” MERGE æ“ä½œ**
```cypher
MERGE (a:User {id: $follower})
ON CREATE SET r.created_at = timestamp()
```

2. **è‡ªæˆ‘è·Ÿè¸ªé˜²æŠ¤**
```rust
if follower_id == followee_id {
    return Err(anyhow::anyhow!("Cannot follow self"));
}
```

3. **å¹‚ç­‰è¾¹åˆ›å»º**
- MERGE ä¿è¯ä¸é‡å¤
- è‡ªåŠ¨å¤„ç†é‡å¤è¯·æ±‚

**âš ï¸ è¯†åˆ«çš„ä¼˜åŒ–æœºä¼š**:

#### é—®é¢˜ 1: N+1 å…³ç³»æŸ¥è¯¢

ç°æœ‰å®ç°:
```rust
// ä¸ºæ¯ä¸ªç”¨æˆ·èŠ‚ç‚¹ç¡®ä¿å­˜åœ¨
async fn ensure_user_node(&self, user_id: Uuid) -> Result<()> {
    self.graph.execute(query(cypher).param("id", user_id.to_string())).await?;
}

// è°ƒç”¨æ–¹å¼ï¼ˆæ½œåœ¨ N+1ï¼‰
pub async fn create_follow(&self, follower_id: Uuid, followee_id: Uuid) -> Result<()> {
    self.ensure_user_node(follower_id).await?;  // Query 1
    self.ensure_user_node(followee_id).await?;  // Query 2
    // ç„¶ååˆ›å»ºå…³ç³» Query 3
}
```

**é—®é¢˜**: ä¸‰æ¬¡å¾€è¿”ç½‘ç»œè°ƒç”¨

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// âœ… åˆå¹¶ä¸ºå•ä¸ª Cypher æ‰§è¡Œ
pub async fn create_follow(&self, follower_id: Uuid, followee_id: Uuid) -> Result<()> {
    let cypher = r#"
        // åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­å®Œæˆæ‰€æœ‰æ“ä½œ
        MERGE (a:User {id: $follower})
        ON CREATE SET a.created_at = timestamp()
        MERGE (b:User {id: $followee})
        ON CREATE SET b.created_at = timestamp()
        MERGE (a)-[r:FOLLOWS]->(b)
        ON CREATE SET r.created_at = timestamp()
        RETURN r.created_at
    "#;

    let mut result = self.graph.execute(
        query(cypher)
            .param("follower", follower_id.to_string())
            .param("followee", followee_id.to_string())
    ).await?;

    while result.next().await?.is_some() {}
    Ok(())
}
```

**æ€§èƒ½æ”¹è¿›**: 3 RTT â†’ 1 RTT (66% å»¶è¿Ÿå‡å°‘)

#### é—®é¢˜ 2: ç¼ºå°‘ Neo4j ç´¢å¼•

**å½“å‰çŠ¶æ€**: Neo4j èŠ‚ç‚¹åˆ›å»ºä½†æ— æ˜¾å¼ç´¢å¼•

**æ¨èçš„ Neo4j ç´¢å¼•**:

```cypher
-- åˆ›å»º User èŠ‚ç‚¹æ ‡ç­¾ç´¢å¼•ï¼ˆè‡ªåŠ¨ï¼‰
CREATE INDEX idx_user_id IF NOT EXISTS
  FOR (u:User) ON (u.id);

-- FOLLOWS å…³ç³»ç´¢å¼•ç”¨äºåå‘æŸ¥è¯¢ï¼ˆè·å–ç²‰ä¸ï¼‰
CREATE INDEX idx_follows_followee IF NOT EXISTS
  FOR ()-[r:FOLLOWS]->(u:User) ON (r.created_at);

-- MUTES å…³ç³»ç´¢å¼•ï¼ˆéšè—å†…å®¹ï¼‰
CREATE INDEX idx_mutes_mutee IF NOT EXISTS
  FOR ()-[r:MUTES]->(u:User) ON (u.id);

-- æ€§èƒ½å…³é”®ï¼šè·Ÿè¸ªå›¾éå†
CREATE INDEX idx_follows_created IF NOT EXISTS
  FOR (u:User)-[r:FOLLOWS]-() ON (r.created_at DESC);
```

#### é—®é¢˜ 3: ç¼ºå°‘æŸ¥è¯¢ä¼˜åŒ–æç¤º

```cypher
-- âŒ ç°æœ‰ Cypher å¯èƒ½å¯¼è‡´ä½æ•ˆè§„åˆ’

-- âœ… æ¨èï¼šæ˜¾å¼è§„åˆ’ä¼˜åŒ–
MATCH (a:User {id: $follower})-[:FOLLOWS]->(b:User {id: $followee})
RETURN COUNT(*) > 0 AS exists
// æ·»åŠ æç¤ºä¼˜åŒ– Neo4j è§„åˆ’å™¨
CALL dbms.stats.retrieve('relationship', 'FOLLOWS')
YIELD rows AS followCount
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šClickHouse ä¼˜åŒ–

### 3.1 å½“å‰ ClickHouse é…ç½®

ğŸ“‚ ä½ç½®: `/backend/clickhouse/`

**å·²æœ‰çš„è¡¨**:
```sql
-- Feed å€™é€‰è¡¨ï¼ˆæ¥è‡ª 002_feed_candidates_tables.sqlï¼‰
-- ç”¨äºæ¨èç³»ç»Ÿå€™é€‰é›†ç”Ÿæˆ
```

### 3.2 ä¼˜åŒ–å»ºè®®

#### é—®é¢˜ 1: ç¼ºå°‘åˆ†åŒºç­–ç•¥

**å½“å‰æ¶æ„**: å•è¡¨å­˜å‚¨æ‰€æœ‰åˆ†ææ•°æ®

**é—®é¢˜**:
- å†·æ•°æ®ï¼ˆ>30 å¤©ï¼‰ä¸åº”ä¸çƒ­æ•°æ®æ··å­˜
- æ— æ³•ç‹¬ç«‹ä¼˜åŒ–è¯»å†™æ€§èƒ½
- å¤‡ä»½/å½’æ¡£ä¸çµæ´»

**æ¨èæ–¹æ¡ˆ**:

```sql
-- âœ… æŒ‰æ—¥æœŸåˆ†åŒºçš„ feed äº‹ä»¶è¡¨
CREATE TABLE IF NOT EXISTS feed_events (
    event_date Date,
    event_id UUID,
    user_id UUID,
    content_id UUID,
    event_type String,  -- 'view', 'like', 'share', 'click'
    score Float32,
    timestamp DateTime,
    properties JSON
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(event_date)  -- æœˆåº¦åˆ†åŒº
ORDER BY (user_id, timestamp)
SETTINGS index_granularity = 8192;

-- âœ… TTL ç­–ç•¥ï¼šè‡ªåŠ¨åˆ é™¤ 90 å¤©å‰çš„æ•°æ®
ALTER TABLE feed_events MODIFY SETTING
  ttl_only_drop_parts = 1;

ALTER TABLE feed_events
  MODIFY TTL event_date + INTERVAL 90 DAY;
```

#### é—®é¢˜ 2: ç¼ºå°‘å‘é‡åŒ–æŸ¥è¯¢ä¼˜åŒ–

ClickHouse é’ˆå¯¹å®½è¡¨ä¼˜åŒ–ï¼Œä½† Nova å¯èƒ½ä½¿ç”¨è¡Œå¯¼å‘æŸ¥è¯¢

**æ¨è**:
```sql
-- âŒ è¡Œå¯¼å‘æŸ¥è¯¢ï¼ˆä½æ•ˆï¼‰
SELECT user_id, content_id, event_type, COUNT(*)
FROM feed_events
WHERE event_date >= '2025-11-01'
GROUP BY user_id, content_id, event_type;

-- âœ… å‘é‡åŒ–æŸ¥è¯¢ï¼ˆé«˜æ•ˆï¼‰
SELECT
    user_id,
    arrayJoin(arrayDistinct(
        groupArrayIf(content_id, event_type = 'view')
    )) AS viewed_content_id,
    COUNT(*) AS view_count
FROM feed_events
WHERE event_date >= '2025-11-01'
GROUP BY user_id
SETTINGS optimize_aggregation_in_order = 1;
```

**æ€§èƒ½æ”¹è¿›**: 3-10xï¼ˆå–å†³äºæ•°æ®å¤§å°ï¼‰

#### é—®é¢˜ 3: ç¼ºå°‘ç‰©åŒ–è§†å›¾ç”¨äºçƒ­ç‚¹æŸ¥è¯¢

```sql
-- âœ… åˆ›å»ºç‰©åŒ–è§†å›¾ç”¨äºçƒ­é—¨å†…å®¹æ’å
CREATE MATERIALIZED VIEW trending_content_mv (
    content_id UUID,
    total_score Float32,
    view_count Int32,
    last_updated DateTime
)
ENGINE = ReplacingMergeTree(last_updated)
PARTITION BY toYYYYMM(last_updated)
ORDER BY total_score DESC
POPULATE AS
SELECT
    content_id,
    SUM(score) AS total_score,
    COUNT(*) AS view_count,
    max(timestamp) AS last_updated
FROM feed_events
WHERE event_date >= today() - 7
GROUP BY content_id;
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šRedis ç¼“å­˜ç­–ç•¥

### 4.1 å½“å‰ç¼“å­˜å®ç°

ğŸ“‚ æ–‡ä»¶: `/graphql-gateway/src/cache/redis_cache.rs`

**âœ… å·²å®ç°**:

1. **è®¢é˜…ç¼“å­˜** (TTL = 60ç§’)
```rust
pub async fn cache_feed_item(&self, feed_id: &str, item: &FeedItem) -> Result<()> {
    redis::cmd("SETEX")
        .arg(&key)
        .arg(self.ttl_seconds)  // TTL é…ç½®
        .query_async(&mut self.redis)
        .await?;
}
```

2. **é€šçŸ¥ PubSub**
```rust
redis::cmd("PUBLISH")
    .arg(&channel)
    .arg(&value)
    .query_async(&mut self.redis)
    .await?;
```

**âš ï¸ ç¼ºå¤±çš„ç­–ç•¥**:

#### é—®é¢˜ 1: è®¡æ•°å™¨ç¼“å­˜ç­–ç•¥ä¸æ¸…æ™°

å½“å‰ PostgreSQL è®¡æ•°æŸ¥è¯¢:
```rust
pub async fn get_like_count(&self, post_id: Uuid) -> Result<i64> {
    let count: i64 = sqlx::query_scalar(
        "SELECT COUNT(*) FROM likes WHERE post_id = $1"
    )
    .bind(post_id)
    .fetch_one(&self.pool)
    .await?;
    Ok(count)
}
```

**é—®é¢˜**: æ¯æ¬¡éƒ½æŸ¥è¯¢æ•°æ®åº“ï¼ˆå½“ Redis ä¸å¯ç”¨æ—¶ï¼‰

**æ¨èçš„å¤šçº§ç¼“å­˜**:

```rust
pub struct CounterCache {
    redis: ConnectionManager,
    db_pool: PgPool,
}

impl CounterCache {
    /// ä¸‰çº§ç¼“å­˜ï¼šL1(Redis) â†’ L2(DB Cache) â†’ L3(Direct)
    pub async fn get_like_count(&self, post_id: Uuid) -> Result<i64> {
        // L1: Redisï¼ˆå¿«ã€æ˜“å¤±ï¼‰
        let key = format!("likes:count:{}", post_id);
        if let Ok(Some(count)) = redis::cmd("GET")
            .arg(&key)
            .query_async::<_, Option<i64>>(&mut self.redis.clone())
            .await
        {
            return Ok(count);
        }

        // L2: PostgreSQL ç¼“å­˜è¡¨ï¼ˆæŒä¹…ã€å‡†ç¡®ï¼‰
        if let Ok(Some(count)) = sqlx::query_scalar::<_, i64>(
            "SELECT like_count FROM post_counters WHERE post_id = $1"
        )
        .bind(post_id)
        .fetch_optional(&self.db_pool)
        .await?
        {
            // å›å†™ Redisï¼ˆå¼‚æ­¥ï¼‰
            let redis_clone = self.redis.clone();
            tokio::spawn(async move {
                let _ = redis::cmd("SETEX")
                    .arg(&key)
                    .arg(3600)  // 1 å°æ—¶ TTL
                    .arg(count)
                    .query_async::<_, ()>(&mut redis_clone.clone())
                    .await;
            });
            return Ok(count);
        }

        // L3: å®æ—¶è®¡æ•°ï¼ˆå¤‡ç”¨ï¼‰
        let count: i64 = sqlx::query_scalar(
            "SELECT COUNT(*) FROM likes WHERE post_id = $1"
        )
        .bind(post_id)
        .fetch_one(&self.db_pool)
        .await?;

        Ok(count)
    }
}
```

**æ¶æ„ä¼˜åŠ¿**:
- Redis æ•…éšœä¸é˜»å¡è¯·æ±‚ï¼ˆå›é€€åˆ° DB ç¼“å­˜ï¼‰
- è‡ªåŠ¨ç¼“å­˜é¢„çƒ­ï¼ˆå¼‚æ­¥å›å†™ï¼‰
- å‡†ç¡®åº¦ä¿è¯ï¼ˆDB ç¼“å­˜åŒæ­¥ï¼‰

#### é—®é¢˜ 2: ç¼ºå°‘ç¼“å­˜å¤±æ•ˆç­–ç•¥

**å½“å‰çŠ¶æ€**: ç¡¬ç¼–ç  TTLï¼ˆ60ç§’ï¼‰

**æ¨è: äº‹ä»¶é©±åŠ¨å¤±æ•ˆ**

```rust
// åœ¨ç‚¹èµæ“ä½œåä¸»åŠ¨å¤±æ•ˆç¼“å­˜
pub async fn create_like(&self, user_id: Uuid, post_id: Uuid) -> Result<Like> {
    // 1. åˆ›å»ºç‚¹èµ
    let like = self.repo.create_like(user_id, post_id).await?;

    // 2. å¤±æ•ˆç›¸å…³ç¼“å­˜
    let keys = vec![
        format!("likes:count:{}", post_id),      // ç‚¹èµè®¡æ•°
        format!("likes:list:{}", post_id),       // ç‚¹èµåˆ—è¡¨
        format!("post:{}:counters", post_id),    // å¸–å­è®¡æ•°èšåˆ
        format!("feed:*"),                       // Feed é¢„çƒ­ï¼ˆæ¨¡å¼å¤±æ•ˆï¼‰
    ];

    for key in keys {
        redis::cmd("DEL")
            .arg(&key)
            .query_async(&mut self.redis)
            .await
            .ok();  // å¤±è´¥ç»§ç»­
    }

    Ok(like)
}
```

#### é—®é¢˜ 3: ç¼ºå°‘ Redis ç›‘æ§

**æ¨èçš„ç›‘æ§æŒ‡æ ‡**:

```rust
pub async fn collect_redis_metrics(&self) {
    // Redis å†…å­˜ä½¿ç”¨
    let info = self.redis.info(Some("memory")).await.unwrap();
    prometheus_counter!("redis_memory_used_bytes", info.memory_used);

    // ç¼“å­˜å‘½ä¸­ç‡
    let hits: u64 = redis::cmd("GET")
        .arg("stats:cache_hits")
        .query_async(&mut self.redis)
        .await
        .unwrap_or(0);

    let misses: u64 = redis::cmd("GET")
        .arg("stats:cache_misses")
        .query_async(&mut self.redis)
        .await
        .unwrap_or(0);

    let hit_rate = hits as f64 / (hits + misses) as f64;
    prometheus_gauge!("redis_cache_hit_rate", hit_rate);

    // è¿æ¥æ± çŠ¶æ€
    prometheus_gauge!("redis_connections_active", self.redis.conn_count());
}
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šæ¶æ„çº§ä¼˜åŒ–å»ºè®®

### 5.1 è¯»å†™åˆ†ç¦»

**å½“å‰çŠ¶æ€**: å•ä¸ª PostgreSQL å®ä¾‹å¤„ç†æ‰€æœ‰è¯»å†™

**å»ºè®®**: è¯»å‰¯æœ¬æ¶æ„ï¼ˆé€‚ç”¨äº AWS RDSï¼‰

```yaml
# PostgreSQL æ¶æ„å‡çº§
Primary DB (å†™):
  - social-service: å†™å…¥ç‚¹èµ/è¯„è®º
  - user-service: å†™å…¥ç”¨æˆ·æ•°æ®
  - Max Connections: 50

Read Replica 1 (åªè¯»):
  - feed-service: æŸ¥è¯¢ Feed å€™é€‰
  - ranking-service: è¯»å–å†å²æ•°æ®
  - Max Connections: 30

Read Replica 2 (åªè¯»):
  - graphql-gateway: ç”¨æˆ·ä¿¡æ¯æŸ¥è¯¢
  - analytics: æŠ¥è¡¨æŸ¥è¯¢
  - Max Connections: 30
```

**é…ç½®ç¤ºä¾‹**:
```rust
pub struct DbPool {
    write: PgPool,      // Primary
    read: Vec<PgPool>,  // Replicas
}

impl DbPool {
    pub async fn execute_write(&self, sql: &str) -> Result<()> {
        self.write.execute(sql).await
    }

    pub async fn execute_read(&self, sql: &str) -> Result<()> {
        // è½®è¯¢è¯»å‰¯æœ¬
        let replica = self.read[rand::random::<usize>() % self.read.len()].clone();
        replica.execute(sql).await
    }
}
```

**æ€§èƒ½æ”¶ç›Š**:
- å†™å…¥ï¼šæ— å½±å“ï¼ˆä¸»å‰¯æœ¬å®Œå…¨åŒæ­¥ï¼‰
- è¯»å–ï¼š3x ååé‡æ”¹è¿›ï¼ˆåˆ†æ•£åˆ°å‰¯æœ¬ï¼‰
- æˆæœ¬ï¼šé¢å¤–çš„å‰¯æœ¬å®ä¾‹è´¹ç”¨

### 5.2 æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆåº”ç”¨çº§ï¼‰

**å½“å‰ç¼ºé™·**: é‡å¤æŸ¥è¯¢ç›¸åŒæ•°æ®

**æ¨è: åŸºäº Dataloader çš„è¯·æ±‚çº§ç¼“å­˜**

```rust
// ä¿®å¤ GraphQL loaders ä¸­çš„è™šæ‹Ÿå®ç°
use async_graphql::dataloader::Loader;
use std::collections::HashMap;

pub struct UserLoader {
    db_pool: PgPool,
}

impl Loader<Uuid> for UserLoader {
    type Value = User;
    type Error = anyhow::Error;

    async fn load(&self, user_ids: &[Uuid]) -> Result<HashMap<Uuid, Self::Value>> {
        // å•æ¬¡æ‰¹é‡æŸ¥è¯¢æ›¿ä»£ N æ¬¡å•ä½“æŸ¥è¯¢
        let users = sqlx::query_as!(
            User,
            "SELECT * FROM users WHERE id = ANY($1::uuid[])",
            &user_ids
        )
        .fetch_all(&self.db_pool)
        .await?;

        Ok(users.into_iter().map(|u| (u.id, u)).collect())
    }
}

pub struct Schema {
    user_loader: UserLoader,
}

// åœ¨ GraphQL ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨
impl Schema {
    pub fn create_context(&self) -> async_graphql::Context {
        let mut context = Context::new(());
        context.insert(DataLoader::new(self.user_loader.clone()));
        context
    }
}
```

### 5.3 å¼‚æ­¥äº‹ä»¶å¤„ç†

**å½“å‰çŠ¶æ€**: åŒæ­¥ç‚¹èµ/è¯„è®ºæ“ä½œå¯èƒ½é˜»å¡å“åº”

**æ¨è**: ä½¿ç”¨ Outbox æ¨¡å¼ + å¼‚æ­¥å¤„ç†

```rust
// å·²éƒ¨åˆ†å®ç°ä½†éœ€è¦ä¼˜åŒ–
pub async fn create_like(&self, user_id: Uuid, post_id: Uuid) -> Result<()> {
    // 1. åˆ›å»ºç‚¹èµï¼ˆå¿«é€Ÿï¼‰
    let like = sqlx::query_as!(
        Like,
        "INSERT INTO likes (user_id, post_id) VALUES ($1, $2) RETURNING *"
    )
    .fetch_one(&self.db_pool)
    .await?;

    // 2. å†™å…¥ Outboxï¼ˆåŸå­æ€§ï¼‰
    sqlx::query!(
        "INSERT INTO outbox (event_type, event_data) VALUES ($1, $2)",
        "liked",
        serde_json::to_string(&LikedEvent { like }).unwrap()
    )
    .execute(&self.db_pool)
    .await?;

    // 3. å¼‚æ­¥å¤„ç†å™¨æ¶ˆè´¹ Outbox
    // - æ›´æ–°è®¡æ•°å™¨ç¼“å­˜
    // - å‘é€é€šçŸ¥
    // - æ›´æ–° Feed å€™é€‰
    // å…¨éƒ¨åœ¨åå°è¿è¡Œï¼ˆä¸é˜»å¡å“åº”ï¼‰

    Ok(())
}
```

---

## ç¬¬å…­éƒ¨åˆ†ï¼šä¼˜åŒ–å®æ–½è·¯çº¿å›¾

### ä¼˜å…ˆçº§ 1: ç«‹å³æ‰§è¡Œï¼ˆ1-2 å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | é¢„æœŸæ”¶ç›Š | æ–‡ä»¶ä½ç½® |
|------|--------|----------|---------|
| æ·»åŠ å¤åˆç´¢å¼• | 2 å°æ—¶ | 10x æŸ¥è¯¢é€Ÿåº¦ | `/migrations/` |
| ä¿®å¤ GraphQL Loaders | 4 å°æ—¶ | æ¶ˆé™¤ N+1 | `/graphql-gateway/src/schema/loaders.rs` |
| å®Œå–„è¿æ¥æ± é…ç½® | 2 å°æ—¶ | æ¶ˆé™¤åƒµå°¸è¿æ¥ | å„æœåŠ¡ `main.rs` |
| Neo4j æŸ¥è¯¢åˆå¹¶ | 4 å°æ—¶ | 3x ç½‘ç»œå¾€è¿”å‡å°‘ | `/graph-service/src/repository/` |

### ä¼˜å…ˆçº§ 2: çŸ­æœŸï¼ˆ2-4 å‘¨ï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | é¢„æœŸæ”¶ç›Š | å®æ–½éš¾åº¦ |
|------|--------|----------|---------|
| å¤šçº§ç¼“å­˜æ¶æ„ | 8 å°æ—¶ | 99.9% å¯ç”¨æ€§ | ä¸­ |
| ClickHouse åˆ†åŒº | 6 å°æ—¶ | å†·æ•°æ®æŸ¥è¯¢ 10x | ä½ |
| Redis ç›‘æ§ | 4 å°æ—¶ | å¯è§‚æµ‹æ€§ | ä½ |
| è¯»å†™åˆ†ç¦» | 16 å°æ—¶ | 3x è¯»å–åå | é«˜ |

### ä¼˜å…ˆçº§ 3: é•¿æœŸï¼ˆ1-2 æœˆï¼‰

| ä»»åŠ¡ | å·¥ä½œé‡ | é¢„æœŸæ”¶ç›Š | å®æ–½éš¾åº¦ |
|------|--------|----------|---------|
| å‘é‡æœç´¢é›†æˆ | 40 å°æ—¶ | è¯­ä¹‰æœç´¢ | é«˜ |
| äº‹ä»¶æº¯æºå®Œæ•´åŒ– | 24 å°æ—¶ | äº‹ä»¶é‡æ”¾ | é«˜ |
| è‡ªåŠ¨æ‰©å±•ç­–ç•¥ | 32 å°æ—¶ | æˆæœ¬ä¼˜åŒ– | é«˜ |

---

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ€§èƒ½åŸºå‡†å’Œç›‘æ§

### 7.1 å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰

```sql
-- å®šæœŸè¿è¡Œç›‘æ§æŸ¥è¯¢

-- 1. ç¼“æ…¢æŸ¥è¯¢æ£€æµ‹
SELECT
    query,
    calls,
    total_time,
    mean_time,
    max_time
FROM pg_stat_statements
WHERE mean_time > 100  -- è¶…è¿‡ 100ms çš„æŸ¥è¯¢
ORDER BY mean_time DESC
LIMIT 10;

-- 2. ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;

-- 3. è¡¨ç»Ÿè®¡ä¿¡æ¯
SELECT
    schemaname,
    tablename,
    n_live_tup,
    n_dead_tup,
    n_tup_ins,
    n_tup_upd,
    n_tup_del,
    last_vacuum,
    last_autovacuum
FROM pg_stat_user_tables
WHERE schemaname != 'pg_catalog'
ORDER BY n_live_tup DESC;

-- 4. è¿æ¥æ± å¥åº·åº¦
SELECT
    datname,
    count(*) as total_connections,
    sum(case when state = 'active' then 1 else 0 end) as active,
    sum(case when state = 'idle' then 1 else 0 end) as idle,
    sum(case when state = 'idle in transaction' then 1 else 0 end) as idle_in_tx
FROM pg_stat_activity
GROUP BY datname;
```

### 7.2 åº”ç”¨çº§ç›‘æ§

```rust
// Prometheus æŒ‡æ ‡

// æ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿ
histogram!("db_query_duration_ms",
    query_start.elapsed().as_millis() as f64,
    "table" => table_name,
    "operation" => operation_type
);

// ç¼“å­˜å‘½ä¸­ç‡
counter!("cache_hits", "cache_type" => "redis");
counter!("cache_misses", "cache_type" => "redis");

// è¿æ¥æ± åˆ©ç”¨ç‡
gauge!("db_pool_connections_active", active_connections);
gauge!("db_pool_connections_idle", idle_connections);
gauge!("db_pool_connections_waiting", waiting_count);

// GraphQL N+1 æ£€æµ‹
counter!("graphql_batch_load_requests",
    "loader" => loader_name,
    "batch_size" => batch_size
);
```

---

## ç¬¬å…«éƒ¨åˆ†ï¼šæˆæœ¬-æ”¶ç›Šåˆ†æ

### 8.1 å®æ–½æˆæœ¬è¯„ä¼°

| ä¼˜åŒ–é¡¹ | å¼€å‘æ—¶é—´ | åŸºç¡€è®¾æ–½æˆæœ¬ | ç»´æŠ¤æˆæœ¬ |
|--------|---------|-------------|---------|
| ç´¢å¼•ä¼˜åŒ– | 2h | 0 | æä½ |
| è¿æ¥æ± è°ƒä¼˜ | 2h | 0 | ä½ |
| GraphQL Loader | 4h | 0 | ä½ |
| å¤šçº§ç¼“å­˜ | 8h | 0 | ä¸­ |
| è¯»å‰¯æœ¬ | 16h | +30-50% | ä¸­ |
| ClickHouse åˆ†åŒº | 6h | 0 | ä½ |

**æ€»åˆå§‹æŠ•èµ„**: ~38 å°æ—¶ + åŸºç¡€è®¾æ–½æˆæœ¬

### 8.2 é¢„æœŸæ”¶ç›Š

#### æ€§èƒ½æ”¹è¿›

```
Feed æŸ¥è¯¢å»¶è¿Ÿ:
  å½“å‰: 500-800ms
  ä¼˜åŒ–å: 100-200ms (60-75% æ”¹è¿›)

N+1 æŸ¥è¯¢æ¶ˆé™¤:
  å½“å‰: GraphQL post_likes æŸ¥è¯¢: 100ms + 10 * 20ms = 300ms
  ä¼˜åŒ–å: 100ms + 1 * 5ms = 105ms (65% æ”¹è¿›)

ç‚¹èµè®¡æ•°æŸ¥è¯¢:
  å½“å‰: 200ms (full scan)
  ä¼˜åŒ–å: 5ms (index) (40x æ”¹è¿›)

API ååé‡:
  å½“å‰: 500 req/s
  ä¼˜åŒ–å: 1500-2000 req/s (3-4x æ”¹è¿›)
```

#### ç”¨æˆ·ä½“éªŒæ”¹è¿›

- Feed åŠ è½½æ—¶é—´: 2-3 ç§’ â†’ 0.5-1 ç§’ âœ…
- ç‚¹èµ/è¯„è®ºå“åº”: 100ms â†’ 10-20ms âœ…
- æœç´¢ç»“æœå»¶è¿Ÿ: 1-2 ç§’ â†’ 200-400ms âœ…

#### æˆæœ¬èŠ‚çœ

```
åŸºç¡€è®¾æ–½ä¼˜åŒ–:
  - å‡å°‘æ•°æ®åº“ CPU ä½¿ç”¨: 60% â†’ 40% (-33%)
  - å‡å°‘ Redis å†…å­˜: å¯èƒ½å‡å°‘å‰¯æœ¬æ•°é‡ (-20%)

å¹´åº¦æˆæœ¬èŠ‚çœ:
  å‡è®¾å½“å‰åŸºç¡€è®¾æ–½æˆæœ¬: $10,000/æœˆ
  ä¼˜åŒ–åæˆæœ¬: $8,000/æœˆ
  å¹´åº¦èŠ‚çœ: $24,000 âœ…
```

---

## ç¬¬ä¹éƒ¨åˆ†ï¼šé£é™©è¯„ä¼°å’Œç¼“è§£

### 9.1 ä¼˜åŒ–é£é™©

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£ç­–ç•¥ |
|------|------|------|---------|
| ç´¢å¼•å˜æ›´å¯¼è‡´ Query Planner é€‰æ‹©ä¸åŒç´¢å¼• | ä¸­ | ä½ | åˆ›å»º CONCURRENTLYï¼Œä½¿ç”¨ EXPLAIN ANALYZE |
| è¯»å‰¯æœ¬å¤åˆ¶å»¶è¿Ÿå¯¼è‡´æ•°æ®ä¸ä¸€è‡´ | ä½ | é«˜ | å…³é”®å†™åè¯»ä½¿ç”¨ä¸»å‰¯æœ¬ï¼Œè®¾ç½®å¤åˆ¶ç›‘æ§ |
| Neo4j äº‹åŠ¡è¶…æ—¶ | ä½ | ä¸­ | å¢åŠ è¶…æ—¶é™åˆ¶ï¼Œç›‘æ§äº‹åŠ¡å»¶è¿Ÿ |
| Redis å†…å­˜æº¢å‡º | ä¸­ | ä¸­ | è®¾ç½® maxmemory + eviction ç­–ç•¥ |

### 9.2 å›æ»šç­–ç•¥

```sql
-- ç´¢å¼•å›æ»šï¼ˆæ— é£é™©ï¼‰
DROP INDEX CONCURRENTLY idx_likes_post_created_id;
DROP INDEX CONCURRENTLY idx_comments_post_created;

-- è¿æ¥æ± å›æ»šï¼ˆæ›´æ–°é…ç½®ï¼‰
DATABASE_MAX_CONNECTIONS=20  # å›åˆ°ä¹‹å‰å€¼

-- è¯»å‰¯æœ¬å›æ»šï¼ˆæŒ‡å‘ä¸»å‰¯æœ¬ï¼‰
REPLICA_HOSTS=primary-db.aws.rds.amazonaws.com

-- ç¼“å­˜å›æ»šï¼ˆæ¸…ç©º Redisï¼‰
redis-cli FLUSHDB
```

---

## ç¬¬åéƒ¨åˆ†ï¼šæ‰§è¡Œæ£€æŸ¥è¡¨

### å‰ç½®æ£€æŸ¥

- [ ] å¤‡ä»½å½“å‰æ•°æ®åº“ï¼ˆè¿ç§»å‰ï¼‰
- [ ] è·å–æ€§èƒ½åŸºå‡†ï¼ˆEXPLAIN ANALYZEï¼‰
- [ ] é€šçŸ¥å›¢é˜Ÿåœæœºçª—å£ï¼ˆå¦‚éœ€è¦ï¼‰
- [ ] å‡†å¤‡å›æ»šè®¡åˆ’

### ä¼˜å…ˆçº§ 1 æ‰§è¡Œ

#### 1.1 æ·»åŠ ç´¢å¼•
```bash
# 1. ç”Ÿæˆè¿ç§»æ–‡ä»¶
touch backend/migrations/201_add_composite_indexes.sql

# 2. åœ¨éç”Ÿäº§ç¯å¢ƒæµ‹è¯•
psql -d nova_dev -f migrations/201_add_composite_indexes.sql

# 3. éªŒè¯ç´¢å¼•åˆ›å»º
SELECT * FROM pg_indexes WHERE indexname LIKE 'idx_%';

# 4. æ£€æŸ¥æŸ¥è¯¢è®¡åˆ’
EXPLAIN ANALYZE SELECT * FROM likes WHERE post_id = 'xxx' ORDER BY created_at DESC LIMIT 20;

# 5. åœ¨ç”Ÿäº§ç¯å¢ƒåº”ç”¨
sqlx migrate run --database-url $DATABASE_URL
```

#### 1.2 ä¿®å¤ GraphQL Loaders
```bash
# 1. å®ç°çœŸå®æ•°æ®åº“æŸ¥è¯¢
vim backend/graphql-gateway/src/schema/loaders.rs

# 2. è¿è¡Œå•å…ƒæµ‹è¯•
cargo test -p graphql-gateway --lib loaders

# 3. è¿è¡Œé›†æˆæµ‹è¯•
cargo test -p graphql-gateway --test graphql_caching_tests

# 4. éƒ¨ç½²å’Œç›‘æ§
# åœ¨ grafana ä¸­æ£€æŸ¥ graphql_batch_load_size æŒ‡æ ‡
```

#### 1.3 ä¼˜åŒ–è¿æ¥æ± 
```bash
# 1. æ›´æ–°é…ç½®
vim backend/user-service/src/db/mod.rs

# 2. åœ¨å¼€å‘ç¯å¢ƒéªŒè¯
cargo test create_pool

# 3. ç›‘æ§è¿æ¥ä½¿ç”¨
SELECT count(*) FROM pg_stat_activity;

# 4. éƒ¨ç½²
kubectl set env deployment/user-service DATABASE_POOL_CONFIG=optimized
```

### éƒ¨ç½²åéªŒè¯

```bash
# éªŒè¯æ€§èƒ½æ”¹è¿›
cargo test --test performance_benchmarks

# ç›‘æ§æ…¢æŸ¥è¯¢
SELECT * FROM pg_stat_statements
WHERE mean_time > 100
ORDER BY mean_time DESC;

# æ£€æŸ¥ç´¢å¼•ç¢ç‰‡
REINDEX INDEX CONCURRENTLY idx_likes_post_created_id;
```

---

## ç»“è®º

Nova çš„æ•°æ®åº“æ¶æ„è®¾è®¡åˆç†ï¼ŒåŸºç¡€è‰¯å¥½ã€‚é€šè¿‡å®æ–½å»ºè®®çš„ä¼˜åŒ–ï¼Œå¯ä»¥è·å¾—ï¼š

- **60-75% çš„æŸ¥è¯¢å»¶è¿Ÿæ”¹è¿›**
- **3-4 å€çš„ API ååé‡æå‡**
- **$24,000 å¹´åº¦æˆæœ¬èŠ‚çœ**
- **æ¶ˆé™¤ N+1 æŸ¥è¯¢é£é™©**
- **ç”Ÿäº§çº§åˆ«çš„å¯é æ€§**

ä¼˜å…ˆçº§ 1 çš„ä¼˜åŒ–æœ€å¿« 1-2 å‘¨å³å¯å®Œæˆéƒ¨ç½²ï¼Œæ”¶ç›Šç«‹ç«¿è§å½±ã€‚å»ºè®®ç«‹å³å¯åŠ¨ç´¢å¼•ä¼˜åŒ–å’Œ GraphQL Loader ä¿®å¤ã€‚

---

**åˆ†æè€…**: Database Optimization Expert
**æŠ¥å‘Šç‰ˆæœ¬**: 1.0
**ä¸‹ä¸€æ¬¡è¯„ä¼°**: ä¼˜åŒ–éƒ¨ç½² 4 å‘¨å
