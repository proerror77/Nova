# Phase 1B å¿«é€Ÿå¯åŠ¨æŒ‡å—

**æœ¬æ–‡æ¡£**: ç«‹å³å¯æ‰§è¡Œçš„ä»£ç ä»»åŠ¡æ¸…å•
**ç›®æ ‡**: æŒ‡å¯¼å·¥ç¨‹å¸ˆä» 0-1 å®Œæˆæ¯ä¸ªæ¨¡å—
**æ—¶é—´**: æ ¹æ®å¹¶è¡Œåº¦ï¼Œ4-6 å‘¨å®Œæˆ

---

## ğŸš€ ç«‹å³å¯åŠ¨: events-service (Week 1)

### æ­¥éª¤ 1: æ‰©å±•äº‹ä»¶åè®®åº“

```bash
# 1. ç¼–è¾‘äº‹ä»¶å®šä¹‰åº“
nano backend/libs/event-schema/src/lib.rs
```

æ·»åŠ ä»¥ä¸‹å†…å®¹:

```rust
// ç»Ÿä¸€ OutboxEvent ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OutboxEvent {
    pub id: Uuid,
    pub aggregate_id: Uuid,
    pub event_type: String,
    pub payload: serde_json::Value,
    pub created_at: DateTime<Utc>,
    pub published_at: Option<DateTime<Utc>>,
    pub retry_count: i32,
    pub last_error: Option<String>,
}

// äº‹ä»¶ä¼˜å…ˆçº§
#[derive(Debug, Clone, Copy, Eq, PartialEq)]
pub enum EventPriority {
    Critical = 0,
    High = 1,
    Normal = 2,
    Low = 3,
}

// æ‰€æœ‰äº‹ä»¶ç±»å‹ (ä¸šåŠ¡é©±åŠ¨çš„å®Œæ•´æ¸…å•)
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "event_type")]
pub enum DomainEvent {
    // Messaging Events
    MessageCreated {
        message_id: Uuid,
        sender_id: Uuid,
        recipient_id: Uuid,
        content: String,
    },
    MessageEdited {
        message_id: Uuid,
        editor_id: Uuid,
        new_content: String,
    },
    MessageDeleted {
        message_id: Uuid,
        deleter_id: Uuid,
    },

    // Reaction Events
    ReactionAdded {
        target_id: Uuid,  // message/post/comment id
        target_type: String,  // "message"/"post"/"comment"
        user_id: Uuid,
        emoji: String,
    },
    ReactionRemoved {
        target_id: Uuid,
        user_id: Uuid,
        emoji: String,
    },

    // Follow Events
    FollowAdded {
        follower_id: Uuid,
        followee_id: Uuid,
    },

    // Content Events
    PostCreated {
        post_id: Uuid,
        author_id: Uuid,
        title: String,
        tags: Vec<String>,
    },

    PostUpdated {
        post_id: Uuid,
        editor_id: Uuid,
    },

    PostDeleted {
        post_id: Uuid,
        deleter_id: Uuid,
    },

    // Add more events as needed...
}
```

### æ­¥éª¤ 2: åˆ›å»º Outbox åå°ä»»åŠ¡

```bash
touch backend/events-service/src/services/outbox.rs
```

```rust
// å®Œæ•´çš„ Outbox å‘å¸ƒå™¨
use tokio::time::{interval, Duration};
use sqlx::PgPool;
use rdkafka::producer::FutureProducer;

pub struct OutboxPublisher {
    db: PgPool,
    kafka_producer: FutureProducer,
    batch_size: i32,
    flush_interval_ms: u64,
}

impl OutboxPublisher {
    pub async fn start(self) {
        let mut ticker = interval(Duration::from_millis(self.flush_interval_ms));

        loop {
            ticker.tick().await;

            if let Err(e) = self.publish_batch().await {
                tracing::error!("Failed to publish outbox batch: {}", e);
            }
        }
    }

    async fn publish_batch(&self) -> Result<()> {
        // 1. æŸ¥è¯¢æœªå‘å¸ƒçš„äº‹ä»¶
        let events: Vec<OutboxEvent> = sqlx::query_as(
            "SELECT * FROM outbox_events
             WHERE published_at IS NULL
             ORDER BY created_at ASC
             LIMIT $1"
        )
        .bind(self.batch_size)
        .fetch_all(&self.db)
        .await?;

        // 2. æ‰¹é‡å‘é€åˆ° Kafka
        let mut send_futures = Vec::new();

        for event in &events {
            let topic = format!("nova_events_{}", event.event_type);
            let key = event.aggregate_id.to_string();
            let payload = serde_json::to_vec(&event.payload)?;

            let future = self.kafka_producer.send(
                rdkafka::message::FutureRecord::to(&topic)
                    .key(&key)
                    .payload(&payload),
                Duration::from_secs(5),
            );

            send_futures.push((event.id, future));
        }

        // 3. ç­‰å¾…æ‰€æœ‰å‘é€å®Œæˆ
        for (event_id, future) in send_futures {
            match future.await {
                Ok(_) => {
                    // æ ‡è®°ä¸ºå·²å‘å¸ƒ
                    sqlx::query(
                        "UPDATE outbox_events SET published_at = NOW() WHERE id = $1"
                    )
                    .bind(event_id)
                    .execute(&self.db)
                    .await?;
                }
                Err(e) => {
                    // æ›´æ–°é‡è¯•è®¡æ•°å’Œé”™è¯¯ä¿¡æ¯
                    sqlx::query(
                        "UPDATE outbox_events
                         SET retry_count = retry_count + 1,
                             last_error = $1
                         WHERE id = $2"
                    )
                    .bind(e.to_string())
                    .bind(event_id)
                    .execute(&self.db)
                    .await?;
                }
            }
        }

        Ok(())
    }
}
```

### æ­¥éª¤ 3: å®ç° events-service gRPC

ç¼–è¾‘ `backend/events-service/src/grpc.rs`:

```rust
#[tonic::async_trait]
impl EventsService for EventsServiceImpl {
    async fn publish_event(
        &self,
        request: tonic::Request<PublishEventRequest>,
    ) -> Result<tonic::Response<PublishEventResponse>, tonic::Status> {
        let req = request.into_inner();

        // 1. éªŒè¯ schema
        self.validate_event_schema(&req.event_type, &req.payload)?;

        // 2. ä¿å­˜åˆ° Outbox
        let event_id = Uuid::new_v4();
        sqlx::query(
            "INSERT INTO outbox_events (id, aggregate_id, event_type, payload, created_at)
             VALUES ($1, $2, $3, $4, NOW())"
        )
        .bind(event_id)
        .bind(req.aggregate_id)
        .bind(&req.event_type)
        .bind(&req.payload)
        .execute(&self.db)
        .await
        .map_err(|e| tonic::Status::internal(e.to_string()))?;

        Ok(tonic::Response::new(PublishEventResponse {
            event_id: event_id.to_string(),
        }))
    }
}
```

---

## ğŸ“‹ æ‰§è¡Œæ¸…å•

### Week 1 ä»»åŠ¡

- [ ] Task 1.1: Outbox æ¨¡å¼æ‰©å±• (Serena + 1 å·¥ç¨‹å¸ˆ, 16h)
  - [ ] æ‰©å±• event-schema
  - [ ] æ·»åŠ æ•°æ®åº“è¿ç§»
  - [ ] æœ¬åœ°æµ‹è¯•

- [ ] Task 1.2: events-service å®ç° (Serena + 1 å·¥ç¨‹å¸ˆ, 32h)
  - [ ] PublishEvent RPC
  - [ ] SubscribeToEvents RPC
  - [ ] Outbox åå°ä»»åŠ¡
  - [ ] é›†æˆæµ‹è¯• (5 ä¸ªæµ‹è¯•ç”¨ä¾‹)

- [ ] Task 1.3: messaging-service user_id æå– (1 å·¥ç¨‹å¸ˆ, 8h)
  - [ ] æ·»åŠ  extract_user_id å‡½æ•°
  - [ ] åœ¨æ‰€æœ‰ RPC ä¸­åº”ç”¨
  - [ ] å•å…ƒæµ‹è¯•

### Week 2 ä»»åŠ¡

- [ ] Task 2.1: notification-service CRUD (2 å·¥ç¨‹å¸ˆ, 24h)
  - [ ] æ•°æ®åº“ schema
  - [ ] CRUD RPC å®ç°
  - [ ] å•å…ƒæµ‹è¯•

- [ ] Task 2.2: search-service å®ç° (2 å·¥ç¨‹å¸ˆ, 20h)
  - [ ] Elasticsearch é›†æˆ
  - [ ] æœç´¢ RPC å®ç°
  - [ ] å»ºè®®å’Œçƒ­æœ

---

## ğŸ”§ æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# 1. å¯åŠ¨ Docker Compose æœåŠ¡
docker-compose -f docker-compose.dev.yml up -d

# 2. è¿è¡Œæ•°æ®åº“è¿ç§»
sqlx migrate run --database-url postgresql://...

# 3. ç¼–è¯‘ events-service
cd backend/events-service
cargo build

# 4. è¿è¡Œ gRPC æœåŠ¡
cargo run

# 5. åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•
grpcurl -plaintext \
  -d '{"event_type":"message_created","aggregate_id":"...","payload":{...}}' \
  localhost:50051 events.EventsService/PublishEvent
```

---

## ğŸ“ å¸¸è§é—®é¢˜

**Q: Outbox è¡¨åœ¨ PostgreSQL ä¸­çš„æ€§èƒ½å½±å“?**
A: ä¼˜åŒ–æ–¹æ¡ˆ:
- ä½¿ç”¨åˆ†åŒºè¡¨ (by date) å‘¨æœŸå½’æ¡£
- å‘å¸ƒæˆåŠŸ 30 å¤©ååˆ é™¤
- åˆ›å»ºç´¢å¼•: `idx_unpublished (published_at, created_at)`

**Q: Kafka Topic è‡ªåŠ¨åˆ›å»º?**
A: æ˜¯çš„ï¼Œé€šè¿‡ Kafka broker çš„ `auto.create.topics.enable=true`

**Q: å¦‚ä½•å¤„ç† duplicate events?**
A: ä½¿ç”¨ `event_id` ä½œä¸ºå¹‚ç­‰é”®ï¼Œæ¶ˆè´¹ç«¯è®°å½• Redis: `processed_events:{event_id}`

**Q: ç½‘ç»œåˆ†åŒºæ—¶æ€ä¹ˆåŠ?**
A:
1. äº‹ä»¶å †ç§¯åœ¨ Outbox è¡¨
2. ç½‘ç»œæ¢å¤åè‡ªåŠ¨å‘é€
3. æ¶ˆè´¹ç«¯éªŒè¯å¹‚ç­‰æ€§

---

## ğŸ¯ éªŒæ”¶æ ‡å‡†

- âœ… Outbox è¡¨æ— æœªå‘å¸ƒäº‹ä»¶ (5+ åˆ†é’Ÿ)
- âœ… Kafka æ¶ˆæ¯åœ¨ 1 ç§’å†…å‡ºç°
- âœ… ä¸å­˜åœ¨é‡å¤äº‹ä»¶
- âœ… äº‹ä»¶é¡ºåºä¿è¯ (per aggregate)
- âœ… ç«¯åˆ°ç«¯å»¶è¿Ÿ < 500ms

---

## ğŸ’¬ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜?
1. æ£€æŸ¥ `/Users/proerror/Documents/nova/IMPLEMENTATION_PLAN_PHASE_1B.md` è¯¦ç»†è®¾è®¡
2. æŸ¥çœ‹ä»£ç æ³¨é‡Šå’Œé”™è¯¯ä¿¡æ¯
3. è¿è¡Œ `cargo test` éªŒè¯é€»è¾‘
4. æŸ¥çœ‹æ—¥å¿—: `tail -f logs/events-service.log`

ç¥ä½ ç¼–ç æ„‰å¿«! ğŸš€
