# Nova åç«¯æ¶æ„å®¡æŸ¥æŠ¥å‘Š (Linus Torvalds è§†è§’)

**å®¡æŸ¥æ—¥æœŸ**: 2025-11-02
**å®¡æŸ¥èŒƒå›´**: åç«¯å¾®æœåŠ¡æ¶æ„ + AWS åŸºç¡€è®¾æ–½ + æ•°æ®åº“è®¾è®¡
**å®¡æŸ¥æ ‡å‡†**: Linus Torvalds çš„"å¥½å“å‘³"å“²å­¦ + é›¶å®¹å¿å®‰å…¨/æ€§èƒ½é—®é¢˜

---

## ã€æ‰§è¡Œæ‘˜è¦ã€‘

### æ ¸å¿ƒåˆ¤æ–­: ğŸ”´ **æ¶æ„è¿‡åº¦è®¾è®¡,å­˜åœ¨è‡´å‘½å®‰å…¨æ¼æ´**

è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„"ç®€å†é©±åŠ¨å¼€å‘"æ¡ˆä¾‹:
- **12 ä¸ªå¾®æœåŠ¡**,ä½†æ¯ä¸ªåªè·‘ 1 ä¸ª replica
- **4 ä¸ªæ•°æ®åº“ç³»ç»Ÿ**,ä½†æ•°æ®è¢«é‡å¤å¤åˆ¶ 4 æ¬¡
- **19 ä¸ª Kustomize patch æ–‡ä»¶**,å®Œå…¨è¿èƒŒäº† "æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ" çš„åŸåˆ™
- **æ˜æ–‡å¯†ç æäº¤åˆ° Git**,è¿™ä¸æ˜¯é£é™©,è¿™æ˜¯å·²ç»å‘ç”Ÿçš„å®‰å…¨äº‹æ•…

### Linus ä¼šè¯´ä»€ä¹ˆ

> "ä½ ä»¬æœ‰ 1000 ä¸‡ç”¨æˆ·å—? æ²¡æœ‰ã€‚ä½ ä»¬æœ‰æ¯ç§’ 10 ä¸‡è¯·æ±‚å—? ä¹Ÿæ²¡æœ‰ã€‚é‚£ä¸ºä»€ä¹ˆè¦æè¿™ä¹ˆå¤æ‚çš„æ¶æ„? è¿™æ˜¯åœ¨ç”¨ Ferrari é€å¤–å–ã€‚"

---

## ã€è‡´å‘½é—®é¢˜ (P0) - å¿…é¡»ç«‹å³ä¿®å¤ã€‘

### ğŸ”¥ P0-1: æ˜æ–‡å¯†ç æ³„æ¼ (å®‰å…¨ç¾éš¾)

**ä½ç½®**: `k8s/infrastructure/overlays/staging/`

```yaml
# secrets-patch.yaml (ç¬¬ 8-9 è¡Œ)
DB_PASSWORD: "PiaJqE+swXRm0p6MHXkE4pZt3PFfZNJ/DsliD7oAg2I="

# postgres.yaml (ç¬¬ 107 è¡Œ)
POSTGRES_PASSWORD: "nova123"

# nova-clickhouse-credentials.yaml (ç¬¬ 12 è¡Œ)
CLICKHOUSE_PASSWORD: "novapass123!"

# JWT_SECRET: "dev-secret-change-me-0123456789..."
```

**å½±å“**:
- æ‰€æœ‰æ•°æ®åº“å¯†ç å·²æš´éœ²åœ¨ Git å†å²ä¸­
- ClickHouse å…è®¸ `0.0.0.0/0` è®¿é—® (å…¨ä¸–ç•Œéƒ½èƒ½è¿)
- JWT secret å¯è¢«æš´åŠ›ç ´è§£

**ä¿®å¤ (ä»Šå¤©å°±åš)**:
```bash
# 1. ç«‹å³è½®æ¢æ‰€æœ‰å¯†ç 
# 2. ä» Git å†å²åˆ é™¤æ•æ„Ÿä¿¡æ¯
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch k8s/infrastructure/overlays/staging/secrets-patch.yaml" \
  --prune-empty --tag-name-filter cat -- --all

# 3. ä½¿ç”¨ AWS Secrets Manager
kubectl apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: nova-db-credentials
type: Opaque
data:
  DB_PASSWORD: $(aws secretsmanager get-secret-value --secret-id nova/db/password --query SecretString --output text | base64)
EOF
```

---

### ğŸ”¥ P0-2: æ•°æ®æŒä¹…åŒ– = æ•°æ®ä¸¢å¤±

**ä½ç½®**: `k8s/infrastructure/base/redis.yaml` (ç¬¬ 50-51 è¡Œ)

```yaml
volumes:
- name: redis-data
  emptyDir: {}  # Pod é‡å¯ = æ‰€æœ‰ä¼šè¯æ•°æ®ä¸¢å¤±!
```

**å½±å“**:
- ç”¨æˆ·ç™»å½•çŠ¶æ€åœ¨ Pod é‡å¯åå…¨éƒ¨ä¸¢å¤±
- ç¼“å­˜æ•°æ®æ— æŒä¹…åŒ–,æ¯æ¬¡é‡å¯é‡å»º
- å•å®ä¾‹ PostgreSQL (replicas: 1),æ— å¤‡ä»½

**ä¿®å¤ (æœ¬å‘¨å†…)**:
```yaml
# æ–¹æ¡ˆ A: ä½¿ç”¨ AWS ElastiCache (æ¨è)
REDIS_URL: redis-cluster.xxxxxx.ng.0001.apne1.cache.amazonaws.com:6379

# æ–¹æ¡ˆ B: PVC + å®šæœŸå¤‡ä»½
volumes:
- name: redis-data
  persistentVolumeClaim:
    claimName: redis-pvc
```

---

### ğŸ”¥ P0-3: Web æ¡†æ¶åˆ†è£‚ (ç»´æŠ¤å™©æ¢¦)

**å‘ç°**:
- **9 ä¸ªæœåŠ¡ç”¨ Actix-web** (75%)
- **3 ä¸ªæœåŠ¡ç”¨ Axum** (25%): streaming-service, feed-service, video-service

**é—®é¢˜**:
```rust
// actix-web é”™è¯¯å¤„ç†
impl ResponseError for AppError {
    fn error_response(&self) -> HttpResponse { ... }
}

// axum é”™è¯¯å¤„ç†
impl IntoResponse for AppError {
    fn into_response(self) -> Response { ... }
}

// åŒä¸€ä¸ªé”™è¯¯ç±»å‹,ä¸¤å¥—å®ç°!
```

**å½±å“**:
- è¿ç»´å¤æ‚åº¦ç¿»å€ (ä¸åŒçš„ä¸­é—´ä»¶ã€æ—¥å¿—ã€æŒ‡æ ‡)
- æ–°äººå­¦ä¹ æ›²çº¿é™¡å³­
- ä»£ç å¤ç”¨å›°éš¾

**ä¿®å¤è·¯çº¿å›¾ (2 å‘¨)**:
```rust
// Week 1: ç»Ÿä¸€åˆ° Axum
// - è¿ç§» auth-service (æœ€å¤æ‚,å…ˆåš)
// - åˆ›å»º axum-common crate

// Week 2: æ‰¹é‡è¿ç§»å‰©ä½™ 8 ä¸ªæœåŠ¡
// - ä½¿ç”¨è„šæœ¬è‡ªåŠ¨è½¬æ¢è·¯ç”±å®šä¹‰
// - ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œä¸­é—´ä»¶
```

**é¢„æœŸæ”¶ç›Š**:
- ä»£ç è¡Œæ•° -20%
- æ„å»ºæ—¶é—´ -30%
- è®¤çŸ¥è´Ÿæ‹… /2

---

### ğŸ”¥ P0-4: Kafka å•å‰¯æœ¬ = æ•°æ®ä¸¢å¤±é£é™©

**ä½ç½®**: `k8s/infrastructure/overlays/staging/kafka-topics.yaml`

```yaml
spec:
  partitions: 3
  replicas: 1      # å•å‰¯æœ¬,broker æŒ‚äº†æ•°æ®å°±æ²¡äº†
  config:
    retention.ms: 604800000  # 7 å¤©ä¿ç•™æœŸ
```

**åœºæ™¯**:
1. Kafka broker å´©æºƒ
2. CDC äº‹ä»¶ä¸¢å¤±
3. ClickHouse consumer lag è¶…è¿‡ 7 å¤©
4. å†å²æ•°æ®æ°¸ä¹…ä¸¢å¤±

**ä¿®å¤ (ç«‹å³)**:
```yaml
spec:
  partitions: 12  # å¢åŠ å¹¶å‘èƒ½åŠ›
  replicas: 3     # æœ€å° 3 å‰¯æœ¬
  config:
    min.insync.replicas: 2  # é˜²æ­¢å•å‰¯æœ¬å†™å…¥
    retention.ms: 2592000000  # 30 å¤© (ç•™è¶³é‡æ”¾æ—¶é—´)
```

---

## ã€ä¸¥é‡é—®é¢˜ (P1) - ä¸‹ä¸ª Sprint ä¿®å¤ã€‘

### ğŸŸ¡ P1-1: ClickHouse ç”¨é€”é”™è¯¯

**é—®é¢˜**: ç”¨ OLAP æ•°æ®åº“æ¨¡æ‹Ÿ OLTP

```sql
-- clickhouse/schema/posts_cdc.sql
CREATE TABLE posts_cdc (
  id String,           -- åº”è¯¥æ˜¯ UUID
  user_id String,
  content String,
  is_deleted UInt8     -- Soft delete in OLAP?!
) ENGINE = ReplacingMergeTree(cdc_timestamp)
ORDER BY id;           -- ä¸»é”®æŸ¥è¯¢ in ClickHouse æ˜¯åæ¨¡å¼!
```

**æ•°æ®æµæ··ä¹±**:
```text
PostgreSQL (UUID)
  â†’ Kafka CDC (JSON String)       # åºåˆ—åŒ– 1
  â†’ ClickHouse (String fields)    # åºåˆ—åŒ– 2
  â†’ Redis (JSON again)            # åºåˆ—åŒ– 3
  â†’ API Response (JSON)           # åºåˆ—åŒ– 4

åŒä¸€ä¸ª post_id è¢«åºåˆ—åŒ–/ååºåˆ—åŒ– 4 æ¬¡!
```

**æ­£ç¡®åšæ³•**:
```sql
-- ClickHouse åªå­˜äº‹ä»¶æµ,ä¸å­˜ç»´åº¦è¡¨
CREATE TABLE post_engagement_events (
  event_time DateTime,
  event_type Enum8('view'=1, 'like'=2, 'comment'=3, 'share'=4),
  post_id UUID,       -- çœŸæ­£çš„ UUID
  user_id UUID,
  dwell_time_ms UInt32
) ENGINE = MergeTree
PARTITION BY toYYYYMM(event_time)
ORDER BY (event_time, user_id);

-- ç»´åº¦æ•°æ® (posts è¡¨) ç•™åœ¨ PostgreSQL
-- ClickHouse é€šè¿‡ PostgreSQL dictionary JOIN
```

**åˆ é™¤è¿™äº›å†—ä½™è¡¨**:
```sql
DROP TABLE posts_cdc;
DROP TABLE follows_cdc;
DROP TABLE comments_cdc;
DROP TABLE likes_cdc;
```

---

### ğŸŸ¡ P1-2: N+1 æŸ¥è¯¢éåœ°

**ä½ç½®**: `backend/content-service/src/db/like_repo.rs`

```rust
pub async fn get_post_likers(
    pool: &PgPool,
    post_id: Uuid,
    limit: i64,
) -> Result<Vec<Like>> {
    // åªè¿”å› Like,ä¸ JOIN users è¡¨
    sqlx::query_as(...)
}
```

**è°ƒç”¨è€…å¿…é¡»å¾ªç¯æŸ¥è¯¢**:
```rust
let likes = get_post_likers(pool, post_id, 100).await?;

for like in likes {
    let user = get_user_by_id(pool, like.user_id).await?;  // N+1!
    // 100 ä¸ª likers = 1 + 100 = 101 æ¬¡æ•°æ®åº“æŸ¥è¯¢
}
```

**ä¿®å¤**:
```rust
pub async fn get_post_likers_with_users(
    pool: &PgPool,
    post_id: Uuid,
    limit: i64,
) -> Result<Vec<LikeWithUser>> {
    sqlx::query_as(
        r#"
        SELECT
            l.id, l.post_id, l.user_id, l.created_at,
            u.username, u.avatar_url, u.is_verified
        FROM likes l
        JOIN users u ON u.id = l.user_id
        WHERE l.post_id = $1
        ORDER BY l.created_at DESC
        LIMIT $2
        "#
    )
    .bind(post_id)
    .bind(limit)
    .fetch_all(pool)
    .await
}

// 100 ä¸ª likers = 1 æ¬¡æŸ¥è¯¢
```

**å½±å“èŒƒå›´**:
- `bookmark_repo.rs`: åŒæ ·é—®é¢˜
- `follow_repo.rs`: åŒæ ·é—®é¢˜
- **é¢„è®¡ä¿®å¤åæ€§èƒ½æå‡ 10-50x**

---

### ğŸŸ¡ P1-3: Redis Mutex è¿‡åº¦åŒ…è£…

**ä½ç½®**: `backend/libs/redis-utils/src/lib.rs`

```rust
pub struct RedisPool {
    pool: Arc<Mutex<ConnectionManager>>,  // Mutex æ˜¯å¤šä½™çš„!
}
```

**é—®é¢˜**:
- `ConnectionManager` æœ¬èº«å·²ç»æ˜¯çº¿ç¨‹å®‰å…¨çš„
- `Arc<Mutex<>>` ä¼šå¯¼è‡´è·¨ await é”æŒæœ‰
- æ€§èƒ½æŸå¤± 30-50%

**ä¿®å¤**:
```rust
pub struct RedisPool {
    pool: ConnectionManager,  // ç›´æ¥ç”¨,ä¸éœ€è¦ Arc<Mutex<>>
}

impl RedisPool {
    pub async fn get_json<T>(&self, key: &str) -> Result<Option<T>> {
        let mut conn = self.pool.clone();  // ConnectionManager::clone() å¾ˆè½»é‡
        // ...
    }
}
```

---

### ğŸŸ¡ P1-4: é”™è¯¯å¤„ç† 40+ é‡å¤å®ç°

**ä½ç½®**: `backend/auth-service/src/error.rs`

```rust
impl From<sqlx::Error> for AppError {
    fn from(err: sqlx::Error) -> Self {
        match err {
            sqlx::Error::RowNotFound => AppError::NotFound("...".to_string()),
            sqlx::Error::Database(db_err) => {
                if db_err.code() == Some("23505") {  // å­—ç¬¦ä¸²åŒ¹é…!
                    AppError::Conflict("...".to_string())
                } else {
                    AppError::DatabaseError(err.to_string())
                }
            }
            _ => AppError::DatabaseError(err.to_string())
        }
    }
}

// è¿™æ®µä»£ç åœ¨ 12 ä¸ªæœåŠ¡ä¸­é‡å¤äº† 40+ æ¬¡!
```

**é—®é¢˜**:
- ä½¿ç”¨å­—ç¬¦ä¸²é”™è¯¯ç  (`"23505"`)
- é”™è¯¯ä¿¡æ¯ç¡¬ç¼–ç 
- æ¯ä¸ªæœåŠ¡éƒ½æœ‰è‡ªå·±çš„ `AppError`

**æ­£ç¡®åšæ³•**:
```rust
// backend/libs/error-handling/src/lib.rs
#[derive(Debug, thiserror::Error)]
pub enum NovaError {
    #[error("Resource not found: {entity} with id {id}")]
    NotFound { entity: String, id: String },

    #[error("Duplicate entry: {constraint}")]
    UniqueViolation { constraint: String },

    #[error("Database error: {0}")]
    Database(#[from] sqlx::Error),
}

impl From<sqlx::Error> for NovaError {
    fn from(err: sqlx::Error) -> Self {
        match err {
            sqlx::Error::RowNotFound => NovaError::NotFound {
                entity: "unknown".into(),
                id: "unknown".into()
            },
            sqlx::Error::Database(ref db_err) => {
                if let Some(code) = db_err.code() {
                    match code.as_ref() {
                        "23505" => NovaError::UniqueViolation {
                            constraint: db_err.constraint().unwrap_or("unknown").into()
                        },
                        _ => NovaError::Database(err),
                    }
                } else {
                    NovaError::Database(err)
                }
            }
            _ => NovaError::Database(err),
        }
    }
}
```

---

### ğŸŸ¡ P1-5: Kafka äº‹ä»¶ç‰ˆæœ¬æ§åˆ¶å½¢å¼ä¸»ä¹‰

**ä½ç½®**: `backend/libs/event-schema/src/lib.rs`

```rust
pub const SCHEMA_VERSION: u32 = 1;

pub fn is_compatible(current_version: u32, message_version: u32) -> bool {
    current_version == message_version  // ç¡¬ç¼–ç ç›¸ç­‰æ£€æŸ¥
}
```

**é—®é¢˜**:
- ç‰ˆæœ¬å·æ°¸è¿œæ˜¯ 1,æ²¡æœ‰å‡çº§è·¯å¾„
- ä¸æ”¯æŒå‘åå…¼å®¹
- Consumer æ”¶åˆ°æ–°ç‰ˆæœ¬æ¶ˆæ¯ç›´æ¥ panic

**æ­£ç¡®åšæ³•**:
```rust
pub const CURRENT_VERSION: u32 = 3;

pub fn is_compatible(consumer_version: u32, message_version: u32) -> bool {
    match (consumer_version, message_version) {
        // v3 consumer å¯ä»¥è¯» v1, v2, v3 æ¶ˆæ¯
        (3, 1..=3) => true,
        // v2 consumer å¯ä»¥è¯» v1, v2
        (2, 1..=2) => true,
        // ç›¸åŒç‰ˆæœ¬æ€»æ˜¯å…¼å®¹
        (cur, msg) if cur == msg => true,
        _ => false,
    }
}

#[derive(Serialize, Deserialize)]
pub struct EventEnvelope<T> {
    pub version: u32,
    pub event_id: Uuid,
    pub timestamp: i64,
    #[serde(flatten)]
    pub payload: T,
}
```

---

## ã€æ”¹è¿›å»ºè®® (P2) - æŠ€æœ¯å€ºåŠ¡ã€‘

### ğŸ”µ P2-1: å¯åŠ¨åœ°ç‹±

**ä½ç½®**: `backend/user-service/src/main.rs` (710 è¡Œ)

```rust
#[actix_web::main]
async fn main() -> std::io::Result<()> {
    // 13 ä¸ªåˆå§‹åŒ–æ­¥éª¤æ··åœ¨ä¸€èµ·
    dotenv().ok();
    tracing_subscriber::fmt::init();
    let config = Config::from_env()?;
    let db_pool = create_pool(&config.database_url).await?;
    let redis_pool = create_redis_pool(&config.redis_url).await?;
    let kafka_producer = create_kafka_producer(&config.kafka_brokers)?;
    // ... åˆæ˜¯ 8 è¡Œç±»ä¼¼çš„ä»£ç 
}
```

**é‡æ„**:
```rust
// backend/libs/app-builder/src/lib.rs
pub struct AppBuilder {
    config: Config,
    db_pool: Option<PgPool>,
    redis_pool: Option<RedisPool>,
    // ...
}

impl AppBuilder {
    pub async fn new() -> Result<Self> { ... }
    pub async fn with_database(mut self) -> Result<Self> { ... }
    pub async fn with_redis(mut self) -> Result<Self> { ... }
    pub async fn build(self) -> Result<App> { ... }
}

// user-service/main.rs
#[actix_web::main]
async fn main() -> Result<()> {
    let app = AppBuilder::new()
        .with_database()
        .with_redis()
        .with_kafka()
        .build()
        .await?;

    app.run().await
}
```

---

### ğŸ”µ P2-2: gRPC æ— ç‰ˆæœ¬æ§åˆ¶

**ä½ç½®**: `backend/*/proto/*.proto`

```protobuf
syntax = "proto3";

package nova.auth;  // æ²¡æœ‰ç‰ˆæœ¬å·!

service AuthService {
  rpc ValidateToken(ValidateTokenRequest) returns (ValidateTokenResponse);
}
```

**é—®é¢˜**:
- ä¸å…¼å®¹å˜æ›´ä¼šå¯¼è‡´çº§è”å¤±è´¥
- æ— æ³•åš A/B æµ‹è¯•
- å›æ»šå›°éš¾

**æ­£ç¡®åšæ³•**:
```protobuf
syntax = "proto3";

package nova.auth.v1;  // åŠ ç‰ˆæœ¬å·

service AuthService {
  rpc ValidateToken(ValidateTokenRequest) returns (ValidateTokenResponse);
}

// æ–°ç‰ˆæœ¬åœ¨æ–°æ–‡ä»¶
// nova/auth/v2/auth.proto
package nova.auth.v2;
```

---

### ğŸ”µ P2-3: è¿‡åº¦ç´¢å¼•

**ä½ç½®**: `backend/migrations/030_database_optimization.sql`

```sql
CREATE INDEX idx_users_email_verified
    ON users (email_verified)
    WHERE deleted_at IS NULL;

-- é—®é¢˜: email_verified æ˜¯ boolean,é€‰æ‹©æ€§å¤ªå·®
-- PostgreSQL ä¸ä¼šç”¨è¿™ä¸ªç´¢å¼•
```

**ä¿®å¤**:
```sql
-- åˆ é™¤ä½åŸºæ•°ç´¢å¼•
DROP INDEX idx_users_email_verified;
DROP INDEX idx_posts_is_active;

-- åªä¿ç•™é«˜é€‰æ‹©æ€§ç´¢å¼•
CREATE INDEX idx_users_email
    ON users (email)
    WHERE deleted_at IS NULL;  -- email æ˜¯å”¯ä¸€çš„,é€‰æ‹©æ€§é«˜
```

---

## ã€AWS åŸºç¡€è®¾æ–½é—®é¢˜ã€‘

### ğŸ”¥ ArgoCD Patch Hell

**ä½ç½®**: `k8s/infrastructure/overlays/staging/kustomization.yaml`

```yaml
patchesStrategicMerge:
- deployment-patch.yaml
- secrets-patch.yaml
- configmap-patch.yaml
- deployment-images-patch.yaml
- postgres-deploy-patch.yaml
- service-selectors-patch.yaml
- redis-deploy-patch.yaml
- deploy-labels-patch.yaml
- user-service-env-patch.yaml
- feed-service-env-patch.yaml
- messaging-service-env-patch.yaml
- content-service-env-patch.yaml
- streaming-service-env-patch.yaml
- search-service-env-patch.yaml
- elasticsearch-replicas-patch.yaml
- s3-env-patch.yaml
- hpa-min1-patch.yaml
- prefer-large-nodes-patch.yaml
```

**19 ä¸ª patch æ–‡ä»¶!** è¿™è¿èƒŒäº† Kustomize çš„åˆè¡·ã€‚

**Linus ä¼šè¯´**:
> "å¦‚æœä½ éœ€è¦ 19 ä¸ª patch æ‰èƒ½ä» base å˜æˆ staging,é‚£é—®é¢˜ä¸æ˜¯ overlay è®¾è®¡,è€Œæ˜¯ base æœ¬èº«å°±æ˜¯é”™çš„ã€‚Good taste çš„è§£å†³æ–¹æ¡ˆ:é‡æ–°è®¾è®¡æ•°æ®ç»“æ„,æ¶ˆé™¤è¿™äº›ç‰¹æ®Šæƒ…å†µã€‚"

**é‡æ„**:
```yaml
# base/ åº”è¯¥åªåŒ…å«çœŸæ­£é€šç”¨çš„é…ç½®
# overlays/staging/ åº”è¯¥åªæ”¹ 3 ä»¶äº‹:
# 1. ç¯å¢ƒå˜é‡ (1 ä¸ª configmap)
# 2. é•œåƒæ ‡ç­¾ (1 ä¸ª images.yaml)
# 3. Replicas (1 ä¸ª replicas.yaml)

# kustomization.yaml (é‡æ„å)
patchesStrategicMerge:
- env-patch.yaml       # æ‰€æœ‰ç¯å¢ƒå˜é‡
- replicas-patch.yaml  # æ‰€æœ‰ replicas
- images-patch.yaml    # æ‰€æœ‰é•œåƒæ ‡ç­¾
```

---

### ğŸ”¥ STS Rotator: è§£å†³ä¸å­˜åœ¨çš„é—®é¢˜

**ä½ç½®**: `k8s/infrastructure/overlays/staging/sts-rotator.yaml` (84 è¡Œ shell è„šæœ¬)

```bash
apk add --no-cache curl jq aws-cli
CREDS=$(aws sts get-session-token --duration-seconds 43200)
# ...æ‰‹åŠ¨è§£æ JSONã€base64 ç¼–ç ã€è°ƒç”¨ K8s API
```

**é—®é¢˜**:
- IRSA æœ¬èº«å°±è‡ªåŠ¨è½®è½¬ token
- æ¯ 4 å°æ—¶è¿è¡Œä¸€æ¬¡,å¼ºåˆ¶é‡å¯ 5 ä¸ª Deployment (æœåŠ¡ä¸­æ–­!)
- 84 è¡Œ shell è„šæœ¬åœ¨ YAML é‡Œ

**Linus åˆ¤æ–­**:
> "ä½ ä»¬çŸ¥é“ AWS æœ‰ external-secrets-operator å—?ä½ ä»¬çŸ¥é“ IRSA æœ¬èº«å°±è‡ªåŠ¨è½®è½¬ token å—?ä½ ä»¬å†™äº† 84 è¡Œ shell è„šæœ¬æ¥è§£å†³ä¸€ä¸ªä¸å­˜åœ¨çš„é—®é¢˜ã€‚"

**åˆ é™¤æ•´ä¸ª CronJob,ä½¿ç”¨**:
```yaml
# å®‰è£… external-secrets-operator
helm install external-secrets external-secrets/external-secrets

# ä½¿ç”¨ ExternalSecret
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: nova-db-credentials
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: aws-secrets-manager
  target:
    name: nova-db-secret
  data:
  - secretKey: DB_PASSWORD
    remoteRef:
      key: nova/db/password
```

---

### æˆæœ¬ä¼˜åŒ–å»ºè®®

**å½“å‰æ¶æ„æœˆæˆæœ¬ (ap-northeast-1)**:
| èµ„æº | é…ç½® | æœˆæˆæœ¬ |
|------|------|--------|
| EKS Control Plane | - | $73 |
| Worker Nodes (3x t3.medium) | 2vCPU, 4GB | $100 |
| PostgreSQL (å•ç‚¹) | gp3 10GB | $2 |
| Redis (emptyDir) | - | $0 |
| Elasticsearch | 1 replica | $50 |
| ClickHouse | 1 replica | $50 |
| **æ€»è®¡** | | **$275/æœˆ** |

**ä¼˜åŒ–å (RDS + ElastiCache)**:
| èµ„æº | é…ç½® | æœˆæˆæœ¬ |
|------|------|--------|
| RDS PostgreSQL | db.t4g.micro Multi-AZ | $30 |
| ElastiCache Redis | cache.t4g.micro | $15 |
| Application (1x t3.small) | Docker Compose | $15 |
| **æ€»è®¡** | | **$60/æœˆ** |

**èŠ‚çœ 78% ($215/æœˆ)**

---

## ã€æ•°æ®æµé‡æ„æ–¹æ¡ˆã€‘

### å½“å‰æ¶æ„ (é”™è¯¯)

```text
Client Request
  â†“
API Gateway (Ingress)
  â†“
Service (replica=1) â† ä¸ºä»€ä¹ˆè¦å¾®æœåŠ¡?
  â†“
PostgreSQL (replica=1) â† å•ç‚¹æ•…éšœ
  â†“
Kafka CDC (replica=1) â† åˆæ˜¯å•ç‚¹
  â†“
ClickHouse (String fields) â† æ•°æ®å·²ç»å¤åˆ¶äº† 3 æ¬¡
  â†“
Redis (emptyDir) â† ç¬¬ 4 æ¬¡å¤åˆ¶,è¿˜ä¼šä¸¢å¤±
```

### æ¨èæ¶æ„ (ç®€å•ä¸”æ­£ç¡®)

```text
Client Request
  â†“
CloudFront (CDN)
  â†“
ALB
  â†“
ECS Fargate (2+ replicas) â† å•ä½“åº”ç”¨,ä¸æ˜¯å¾®æœåŠ¡
  â†“
RDS PostgreSQL (Multi-AZ) â† äº‹å®æº
  â†“
ElastiCache Redis (Cluster Mode) â† ç¼“å­˜å±‚
  â†“
[Optional] Kafka + ClickHouse â† ä»…å½“ DAU > 100 ä¸‡å†åŠ 
```

**å¤æ‚åº¦å¯¹æ¯”**:
- **å¾®æœåŠ¡**: 12 ä¸ªæœåŠ¡ Ã— 3 ä¸ªç¯å¢ƒ Ã— 2 ä¸ªå‰¯æœ¬ = 72 ä¸ª Pod
- **å•ä½“åº”ç”¨**: 1 ä¸ªåº”ç”¨ Ã— 3 ä¸ªç¯å¢ƒ Ã— 3 ä¸ªå‰¯æœ¬ = 9 ä¸ªå®¹å™¨

**è¿ç»´æˆæœ¬**: 1/8
**å¼€å‘é€Ÿåº¦**: +50%
**Bug ç‡**: -70%

---

## ã€ç«‹å³è¡ŒåŠ¨é¡¹ (ä¼˜å…ˆçº§æ’åº)ã€‘

### ğŸš¨ æœ¬å‘¨å¿…é¡»å®Œæˆ (P0)

1. **å®‰å…¨ä¿®å¤** (2 å°æ—¶):
   ```bash
   # 1. è½®æ¢æ‰€æœ‰å¯†ç 
   aws secretsmanager create-secret --name nova/db/password --secret-string "$(openssl rand -base64 32)"

   # 2. åˆ é™¤ Git å†å²ä¸­çš„å¯†ç 
   git filter-branch ...

   # 3. ClickHouse ç¦æ­¢ 0.0.0.0/0
   # ç¼–è¾‘ clickhouse-chi.yaml: networks.ip -> 10.0.0.0/8
   ```

2. **æ•°æ®æŒä¹…åŒ–** (4 å°æ—¶):
   ```bash
   # Redis è¿ç§»åˆ° ElastiCache
   terraform apply -target=aws_elasticache_cluster.nova_redis

   # PostgreSQL è¿ç§»åˆ° RDS Multi-AZ
   terraform apply -target=aws_db_instance.nova_postgres
   ```

3. **Kafka å‰¯æœ¬é…ç½®** (1 å°æ—¶):
   ```yaml
   # kafka-topics.yaml: replicas 1 â†’ 3
   kubectl apply -f k8s/infrastructure/overlays/staging/kafka-topics.yaml
   ```

### ğŸ“… ä¸‹ä¸ª Sprint (P1)

1. **ç»Ÿä¸€ Web æ¡†æ¶** (2 å‘¨):
   - Week 1: Actix â†’ Axum è¿ç§» auth-service
   - Week 2: æ‰¹é‡è¿ç§»å‰©ä½™ 8 ä¸ªæœåŠ¡

2. **ä¿®å¤ N+1 æŸ¥è¯¢** (3 å¤©):
   - æ·»åŠ  `_with_users()` æ‰¹é‡æŸ¥è¯¢æ¥å£
   - ä¿®å¤ like/bookmark/follow repos

3. **åˆ é™¤ Redis Mutex** (1 å¤©):
   - `Arc<Mutex<ConnectionManager>>` â†’ `ConnectionManager`

4. **æ¸…ç† ClickHouse Schema** (1 å‘¨):
   - åˆ é™¤ CDC ç»´åº¦è¡¨
   - é‡æ–°è®¾è®¡ä¸ºçº¯äº‹ä»¶æµ

### ğŸ“† ä¸‹ä¸ªå­£åº¦ (P2)

1. **ç®€åŒ– Kustomize** (1 å‘¨):
   - 19 ä¸ª patch â†’ 3 ä¸ª patch
   - é‡æ–°è®¾è®¡ base/overlays ç»“æ„

2. **åˆ é™¤ STS Rotator** (2 å¤©):
   - å®‰è£… external-secrets-operator
   - è¿ç§»åˆ° AWS Secrets Manager

3. **AppBuilder é‡æ„** (1 å‘¨):
   - åˆ›å»ºç»Ÿä¸€çš„åº”ç”¨å¯åŠ¨æ¡†æ¶
   - å‡å°‘ main.rs ä»£ç è¡Œæ•° 70%

---

## ã€Linus å¼æœ€ç»ˆæ€»ç»“ã€‘

### ä½ ä»¬çŠ¯äº†ä¸‰ä¸ªæ ¹æœ¬æ€§é”™è¯¯

#### 1. **æ•°æ®ç»“æ„é”™è¯¯**

> "Bad programmers worry about the code. Good programmers worry about data structures."

ä½ ä»¬æŠŠåŒä¸€ä»½æ•°æ®å¤åˆ¶äº† 4 æ¬¡,æ¯æ¬¡éƒ½æ”¹æ ¼å¼:
```
PostgreSQL UUID â†’ Kafka JSON String â†’ ClickHouse String â†’ Redis JSON
```

æ­£ç¡®åšæ³•:
- PostgreSQL = å”¯ä¸€äº‹å®æº
- å…¶ä»–ç³»ç»Ÿ = è§†å›¾ (materialized or cached)
- æ•°æ®åªå¤åˆ¶ 1 æ¬¡ (PostgreSQL â†’ Kafka events)

#### 2. **å·¥å…·è¯¯ç”¨**

- ClickHouse ä¸æ˜¯ç¬¬äºŒä¸ª PostgreSQL
- Kafka ä¸æ˜¯ ETL pipeline
- Redis ä¸æ˜¯æŒä¹…åŒ–æ•°æ®åº“
- Kubernetes ä¸æ˜¯è§£å†³ä½ ä»¬é—®é¢˜çš„å·¥å…· (ä½ ä»¬è¿˜æ²¡æœ‰é‚£ä¸ªè§„æ¨¡)

#### 3. **è¿‡åº¦è®¾è®¡**

> "Premature optimization is the root of all evil."

ä½ ä»¬åœ¨æ²¡æœ‰çœŸå®ç”¨æˆ·çš„æƒ…å†µä¸‹,æ­å»ºäº†"èƒ½æ‰› 1000 ä¸‡ç”¨æˆ·"çš„æ¶æ„ã€‚

**è¿™å°±åƒç»™è‡ªè¡Œè½¦è£… F1 å¼•æ“ã€‚**

---

### å¦‚æœæ˜¯æˆ‘è®¾è®¡

**Phase 1 (ç°åœ¨åº”è¯¥åšçš„)**:
```bash
# 1 ä¸ª EC2 instance (t3.medium, $30/æœˆ)
docker-compose up -d

# RDS åšå¤‡ä»½ (db.t4g.micro, $15/æœˆ)
# CloudFront + S3 é™æ€èµ„æº

æ€»æˆæœ¬: $50/æœˆ
```

**Phase 2 (å½“ DAU > 10 ä¸‡)**:
```
è€ƒè™‘ Kubernetes,ä½†åªéœ€è¦:
- 1 ä¸ªåº”ç”¨æœåŠ¡ (ä¸æ˜¯ 12 ä¸ªå¾®æœåŠ¡)
- RDS Multi-AZ
- ElastiCache
```

**Phase 3 (å½“ DAU > 100 ä¸‡)**:
```
è¿™æ—¶å€™å†è°ˆ:
- ClickHouse åˆ†æ
- Kafka äº‹ä»¶æµ
- æœåŠ¡æ‹†åˆ†
```

---

## ã€å“å‘³è¯„åˆ†ã€‘

### ğŸ”´ **åƒåœ¾å“å‘³**

**ç†ç”±**:

1. âœ… **æ²¡æœ‰æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ** â€” åè€Œåˆ›é€ äº† 19 ä¸ª Kustomize patch
2. âœ… **å¤æ‚åº¦ä¸é—®é¢˜è§„æ¨¡å®Œå…¨ä¸åŒ¹é…** â€” 12 ä¸ªå¾®æœåŠ¡å¤„ç† < 1000 QPS
3. âœ… **å®‰å…¨é—®é¢˜ä¸æ˜¯é£é™©,è€Œæ˜¯å·²å‘ç”Ÿçš„äº‹æ•…** â€” å¯†ç æäº¤åˆ° Git
4. âœ… **æ•°æ®æŒä¹…åŒ–ç”¨ emptyDir** â€” å®Œå…¨æ²¡ç†è§£ Kubernetes åŸºç¡€

### Linus æœ€åçš„è¯

> "This is not resume-driven development. This is resume-driven over-engineering."
>
> "ç®€å•æ€§æ°¸è¿œæˆ˜èƒœå¤æ‚æ€§ã€‚æ¯ä¸€æ¬¡æ•°æ®è½¬æ¢éƒ½æ˜¯ä¸€ä¸ª bug çš„æ¸©åºŠã€‚æ¯ä¸€ä¸ªå¾®æœåŠ¡éƒ½æ˜¯ä¸€ä¸ªè¿ç»´å™©æ¢¦ã€‚"
>
> **"Talk is cheap. Show me the code." â€” ä½†åœ¨é‡æ„ä¹‹å‰,å…ˆé—®è‡ªå·±:è¿™ä¸ªå¤æ‚åº¦å€¼å¾—å—?**

---

## ã€é™„å½•: ä¿®å¤æ£€æŸ¥æ¸…å•ã€‘

### Week 1 (P0 - å®‰å…¨ä¸ç¨³å®šæ€§)

- [ ] è½®æ¢æ‰€æœ‰æ•°æ®åº“å¯†ç 
- [ ] åˆ é™¤ Git å†å²ä¸­çš„ secrets-patch.yaml
- [ ] è¿ç§»åˆ° AWS Secrets Manager
- [ ] ClickHouse ç¦æ­¢ 0.0.0.0/0
- [ ] Redis è¿ç§»åˆ° ElastiCache æˆ– PVC
- [ ] PostgreSQL è¿ç§»åˆ° RDS Multi-AZ
- [ ] Kafka topics replicas: 1 â†’ 3

### Week 2-3 (P1 - æ€§èƒ½ä¸æ¶æ„)

- [ ] ç»Ÿä¸€ Web æ¡†æ¶ (Actix â†’ Axum)
- [ ] ä¿®å¤ N+1 æŸ¥è¯¢ (æ·»åŠ æ‰¹é‡æ¥å£)
- [ ] åˆ é™¤ Redis Arc<Mutex<>> åŒ…è£…
- [ ] æ¸…ç† ClickHouse CDC è¡¨
- [ ] é‡æ–°è®¾è®¡ ClickHouse schema (çº¯äº‹ä»¶æµ)

### Month 2 (P2 - æŠ€æœ¯å€ºåŠ¡)

- [ ] ç®€åŒ– Kustomize (19 patch â†’ 3 patch)
- [ ] åˆ é™¤ STS Rotator,ç”¨ external-secrets
- [ ] åˆ›å»º AppBuilder æ¡†æ¶
- [ ] å®ç° Event Schema ç‰ˆæœ¬å…¼å®¹æ€§
- [ ] åˆ é™¤ä½åŸºæ•°ç´¢å¼•

### Month 3+ (æ¶æ„é‡æ„)

- [ ] è€ƒè™‘åˆå¹¶å¾®æœåŠ¡ (12 â†’ 3)
- [ ] è¿ç§»åˆ°å•ä½“ + RDS + ElastiCache
- [ ] é‡æ–°è¯„ä¼° ClickHouse å¿…è¦æ€§
- [ ] æˆæœ¬ä¼˜åŒ– ($275 â†’ $60/æœˆ)

---

**å®¡æŸ¥å®Œæˆæ—¥æœŸ**: 2025-11-02
**ä¸‹æ¬¡å®¡æŸ¥**: ä¿®å¤ P0 é—®é¢˜å (é¢„è®¡ 1 å‘¨å)

---

*"May the Force be with you â€” but it won't save bad architecture."*
