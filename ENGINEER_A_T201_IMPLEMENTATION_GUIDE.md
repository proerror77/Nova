# å·¥ç¨‹å¸ˆA - T201 Kafkaæ¶ˆè´¹è€…å®ç°æŒ‡å—

**ä»»åŠ¡**: T201 - Kafkaæ¶ˆè´¹è€… + æ‰¹å¤„ç†
**åˆ†é…æ—¶é—´**: 16 å°æ—¶ (å‘¨ä¸‰-å‘¨å››)
**ç›®æ ‡**: 30+ å•å…ƒæµ‹è¯•ï¼ŒP95å»¶è¿Ÿ < 500ms

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

```bash
# 1. åˆ‡æ¢åˆ°ç‰¹æ€§åˆ†æ”¯
git checkout feature/T201-kafka-notifications
git pull origin feature/T201-kafka-notifications

# 2. éªŒè¯æ¡†æ¶ä»£ç å·²åŠ è½½
cd backend/user-service/src/services/notifications
ls -la kafka_consumer.rs  # åº”è¯¥å­˜åœ¨

# 3. ç¼–è¯‘éªŒè¯æ¡†æ¶
cargo build --lib --release

# 4. è¿è¡Œç°æœ‰å•å…ƒæµ‹è¯•
cargo test kafka_consumer --lib
```

---

## ğŸ“‹ å®ç°ä»»åŠ¡åˆ†è§£

### ç¬¬1éƒ¨åˆ†ï¼šKafkaè¿æ¥ç®¡ç† (4å°æ—¶)

**ç›®æ ‡**: å»ºç«‹åˆ°Kafka brokerçš„è¿æ¥å¹¶ç®¡ç†æ¶ˆè´¹è€…ç”Ÿå‘½å‘¨æœŸ

**æ–‡ä»¶**: `kafka_consumer.rs`

**å¾…å®ç°æ–¹æ³•**:
```rust
impl KafkaNotificationConsumer {
    /// å¯åŠ¨æ¶ˆè´¹å¾ªç¯ (éœ€è¦å®ç°)
    pub async fn start(&mut self) -> Result<(), String> {
        // TODO: Step 1 - åˆ›å»º Kafka æ¶ˆè´¹è€…è¿æ¥
        // ä½¿ç”¨ rdkafka åº“
        // let consumer: StreamConsumer = ClientConfig::new()
        //     .set("bootstrap.servers", &self.broker)
        //     .set("group.id", &self.group_id)
        //     .set("auto.offset.reset", "latest")
        //     .create()?;

        // TODO: Step 2 - è®¢é˜…ä¸»é¢˜
        // consumer.subscribe(&[&self.topic])?;

        // TODO: Step 3 - å¯åŠ¨æ¶ˆè´¹å¾ªç¯
        // loop {
        //   match consumer.recv().await {
        //     Ok(msg) => { /* å¤„ç†æ¶ˆæ¯ */ },
        //     Err(e) => { /* å¤„ç†é”™è¯¯ */ }
        //   }
        // }

        Err("Not yet implemented".to_string())
    }
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æˆåŠŸè¿æ¥åˆ° Kafka broker (localhost:9092)
- [ ] è®¢é˜… "notifications" ä¸»é¢˜
- [ ] æ¶ˆè´¹å¾ªç¯è¿è¡Œä¸è¶…è¿‡ 100ms/è½®
- [ ] é”™è¯¯æ—¶è‡ªåŠ¨é‡è¿ (ä½¿ç”¨ RetryPolicy)

**å•å…ƒæµ‹è¯•** (3ä¸ª):
```rust
#[tokio::test]
async fn test_kafka_consumer_connection() { }

#[tokio::test]
async fn test_kafka_consumer_subscribe() { }

#[tokio::test]
async fn test_kafka_consumer_reconnect_on_failure() { }
```

---

### ç¬¬2éƒ¨åˆ†ï¼šæ‰¹å¤„ç†å¼•æ“ (8å°æ—¶)

**ç›®æ ‡**: å®ç°é«˜æ•ˆçš„é€šçŸ¥æ‰¹å¤„ç†ï¼Œæ”¯æŒå¤§å°å’Œæ—¶é—´ä¸¤ç§åˆ·æ–°ç­–ç•¥

**å…³é”®å®ç°**:

#### 2.1 æ‰¹å¤„ç†å¾ªç¯ (3å°æ—¶)

```rust
pub async fn consume_and_batch(&mut self) -> Result<(), String> {
    let mut batch = NotificationBatch::new();
    let flush_interval = Duration::from_millis(self.flush_interval_ms);

    loop {
        // TODO: å®ç°ï¼š
        // 1. ä» Kafka æ¶ˆè´¹ä¸€æ¡æ¶ˆæ¯
        // 2. è§£æä¸º KafkaNotification
        // 3. æ·»åŠ åˆ°æ‰¹å¤„ç†
        // 4. æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆ·æ–° (å¤§å°æˆ–æ—¶é—´)
        // 5. å¦‚æœæ˜¯ - åˆ·æ–°æ‰¹å¤„ç†åˆ°æ•°æ®åº“
        // 6. è®°å½•æŒ‡æ ‡

        tokio::time::sleep(Duration::from_millis(10)).await;
    }
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ‰¹å¤„ç†å¤§å°è¾¾åˆ° 100 æ—¶è‡ªåŠ¨åˆ·æ–°
- [ ] æ‰¹å¤„ç†æ—¶é—´è¶…è¿‡ 5 ç§’æ—¶è‡ªåŠ¨åˆ·æ–°
- [ ] ååé‡ â‰¥ 10,000 msg/sec
- [ ] å†…å­˜ä½¿ç”¨ç¨³å®š < 100MB

**å•å…ƒæµ‹è¯•** (4ä¸ª):
```rust
#[tokio::test]
async fn test_batch_consumes_messages() { }

#[tokio::test]
async fn test_batch_flushes_on_size() { }

#[tokio::test]
async fn test_batch_flushes_on_time() { }

#[tokio::test]
async fn test_batch_throughput_benchmark() { }
```

#### 2.2 æ•°æ®åº“é›†æˆ (3å°æ—¶)

```rust
impl NotificationBatch {
    pub async fn flush(&self) -> Result<usize, String> {
        // TODO: å®ç°ï¼š
        // 1. æ„å»ºæ‰¹é‡æ’å…¥ SQL
        // INSERT INTO notifications (user_id, event_type, title, body, created_at)
        // VALUES ($1, $2, $3, $4, $5), ...

        // 2. æ‰§è¡ŒæŸ¥è¯¢
        // 3. å¤„ç†é”™è¯¯å’Œå†²çª
        // 4. è¿”å›æˆåŠŸæ’å…¥çš„è¡Œæ•°

        // æ€§èƒ½ç›®æ ‡ï¼š
        // - 1,000 æ¡è®°å½• < 50ms
        // - 10,000 æ¡è®°å½• < 200ms

        Ok(self.notifications.len())
    }
}
```

**å•å…ƒæµ‹è¯•** (2ä¸ª):
```rust
#[tokio::test]
async fn test_batch_flush_to_database() { }

#[tokio::test]
async fn test_batch_flush_performance() { }
```

#### 2.3 æ‰¹å¤„ç†ä¼˜åŒ– (2å°æ—¶)

- å®ç°è¿æ¥æ± 
- æ·»åŠ äº‹åŠ¡æ”¯æŒ
- å®ç°éƒ¨åˆ†å¤±è´¥å¤„ç†

**å•å…ƒæµ‹è¯•** (2ä¸ª):
```rust
#[tokio::test]
async fn test_connection_pool_reuse() { }

#[tokio::test]
async fn test_partial_failure_handling() { }
```

---

### ç¬¬3éƒ¨åˆ†ï¼šé”™è¯¯å¤„ç†å’Œé‡è¯• (4å°æ—¶)

**ç›®æ ‡**: å®ç°ç”Ÿäº§çº§åˆ«çš„é”™è¯¯æ¢å¤æœºåˆ¶

#### 3.1 é‡è¯•é€»è¾‘

```rust
impl KafkaNotificationConsumer {
    pub async fn process_message_with_retry(
        &self,
        message: KafkaNotification,
    ) -> Result<(), String> {
        let mut attempt = 0;

        loop {
            match self.process_message(message.clone(), attempt).await {
                Ok(_) => return Ok(()),
                Err(e) => {
                    if !self.retry_policy.should_retry(attempt) {
                        return Err(format!("Failed after {} attempts: {}", attempt, e));
                    }

                    let backoff = self.retry_policy.get_backoff(attempt);
                    tokio::time::sleep(backoff).await;
                    attempt += 1;
                }
            }
        }
    }
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æœ€å¤šé‡è¯• 3 æ¬¡ (å¯é…ç½®)
- [ ] æŒ‡æ•°é€€é¿: 100ms â†’ 200ms â†’ 400ms
- [ ] æœ€å¤§é€€é¿æ—¶é—´ 5 ç§’

**å•å…ƒæµ‹è¯•** (3ä¸ª):
```rust
#[tokio::test]
async fn test_retry_backoff() { }

#[tokio::test]
async fn test_retry_max_attempts() { }

#[tokio::test]
async fn test_retry_eventual_failure() { }
```

#### 3.2 æ–­è·¯å™¨

```rust
pub struct CircuitBreaker {
    failure_count: AtomicU32,
    last_failure: Arc<Mutex<Option<Instant>>>,
    threshold: u32,
    timeout: Duration,
}

impl CircuitBreaker {
    pub async fn execute<F, T>(&self, f: F) -> Result<T, String>
    where
        F: FnOnce() -> futures::future::BoxFuture<'static, Result<T, String>>,
    {
        // TODO: å®ç°æ–­è·¯å™¨é€»è¾‘
        // 1. æ£€æŸ¥æ˜¯å¦åº”è¯¥å¼€å¯æ–­è·¯å™¨
        // 2. å¦‚æœå·²å¼€å¯ - è¿”å›é”™è¯¯
        // 3. å¦åˆ™ - æ‰§è¡Œå‡½æ•°
        // 4. å¦‚æœå¤±è´¥ - å¢åŠ å¤±è´¥è®¡æ•°
        // 5. å¦‚æœæˆåŠŸ - é‡ç½®å¤±è´¥è®¡æ•°
    }
}
```

**å•å…ƒæµ‹è¯•** (3ä¸ª):
```rust
#[tokio::test]
async fn test_circuit_breaker_opens_on_failures() { }

#[tokio::test]
async fn test_circuit_breaker_resets_on_success() { }

#[tokio::test]
async fn test_circuit_breaker_backoff() { }
```

---

## ğŸ§ª æµ‹è¯•æ¸…å•

### éœ€è¦å®ç°çš„æµ‹è¯• (30+)

**Kafkaè¿æ¥** (5ä¸ª):
- [ ] Connection establishment
- [ ] Topic subscription
- [ ] Message consumption
- [ ] Automatic reconnection
- [ ] Connection timeout handling

**æ‰¹å¤„ç†** (10ä¸ª):
- [ ] Batch creation
- [ ] Batch addition
- [ ] Flush on size
- [ ] Flush on time
- [ ] Database insertion
- [ ] Performance benchmark
- [ ] Connection pooling
- [ ] Transaction support
- [ ] Partial failure handling
- [ ] Memory efficiency

**é‡è¯•æœºåˆ¶** (8ä¸ª):
- [ ] Exponential backoff
- [ ] Max retries enforcement
- [ ] Retry success recovery
- [ ] Retry eventual failure
- [ ] Circuit breaker open
- [ ] Circuit breaker reset
- [ ] Circuit breaker backoff
- [ ] Dead letter queue

**ç«¯åˆ°ç«¯** (5ä¸ª+):
- [ ] Full notification flow
- [ ] High throughput (10k msg/sec)
- [ ] Error recovery
- [ ] Graceful shutdown
- [ ] Performance under load

### æµ‹è¯•è¿è¡Œå‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰ T201 æµ‹è¯•
cargo test kafka_consumer --lib -- --nocapture

# è¿è¡Œç‰¹å®šæµ‹è¯•
cargo test kafka_consumer::tests::test_kafka_consumer_connection --lib

# è¿è¡Œå¸¦æ€§èƒ½åŸºå‡†çš„æµ‹è¯•
cargo test --lib --release -- --nocapture --test-threads=1

# æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡
cargo tarpaulin --lib --out Html
```

---

## ğŸ“Š æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | éªŒè¯æ–¹æ³• |
|------|------|---------|
| æ¶ˆè´¹å»¶è¿Ÿ (P95) | < 100ms | åŸºå‡†æµ‹è¯• |
| æ‰¹åˆ·æ–°å»¶è¿Ÿ (P95) | < 200ms | æ•°æ®åº“æµ‹è¯• |
| ååé‡ | â‰¥ 10k msg/sec | è´Ÿè½½æµ‹è¯• |
| å†…å­˜ä½¿ç”¨ | < 100MB | å†…å­˜åˆ†æ |
| é”™è¯¯æ¢å¤æ—¶é—´ | < 5 ç§’ | æ•…éšœæ³¨å…¥æµ‹è¯• |

---

## ğŸ”§ å¼€å‘ç¯å¢ƒè®¾ç½®

### å¿…éœ€ä¾èµ–

```toml
# Cargo.toml
[dependencies]
rdkafka = "0.35"          # Kafka client
tokio = { version = "1", features = ["full"] }
serde_json = "1.0"
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
```

### Kafka æœ¬åœ°è®¾ç½®

```bash
# å¯åŠ¨ Docker Compose ä¸­çš„ Kafka
docker-compose up kafka zookeeper

# åˆ›å»ºä¸»é¢˜
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic notifications \
  --partitions 3 \
  --replication-factor 1

# éªŒè¯ä¸»é¢˜
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

---

## ğŸ“… æ¯æ—¥æ£€æŸ¥ç‚¹

### å‘¨ä¸‰ (Day 1) - å‰ 8 å°æ—¶
- [ ] Kafka è¿æ¥å»ºç«‹
- [ ] æ¶ˆè´¹å¾ªç¯è¿è¡Œ
- [ ] 3 ä¸ªè¿æ¥æµ‹è¯•é€šè¿‡
- ç›®æ ‡ä»£ç è¡Œæ•°: ~150 è¡Œ

### å‘¨å›› (Day 2) - å 8 å°æ—¶
- [ ] æ‰¹å¤„ç†é€»è¾‘å®Œæˆ
- [ ] æ•°æ®åº“é›†æˆå®Œæˆ
- [ ] é‡è¯•æœºåˆ¶å®Œæˆ
- [ ] æ‰€æœ‰ 30+ æµ‹è¯•é€šè¿‡
- ç›®æ ‡ä»£ç è¡Œæ•°: ~400 è¡Œ

---

## ğŸ¯ å®Œæˆæ ‡å‡†

âœ… **T201 å®Œæˆå®šä¹‰**:
1. `KafkaNotificationConsumer::start()` å®Œå…¨å®ç°
2. `NotificationBatch::flush()` å®Œå…¨å®ç°
3. 30+ å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡
4. æ€§èƒ½ç›®æ ‡å…¨éƒ¨è¾¾æˆ:
   - P95 æ¶ˆè´¹å»¶è¿Ÿ < 100ms
   - P95 æ‰¹åˆ·æ–°å»¶è¿Ÿ < 200ms
   - ååé‡ â‰¥ 10k msg/sec
5. ä»£ç å®¡æŸ¥é€šè¿‡
6. å®Œæ•´æ–‡æ¡£äº¤ä»˜

---

## ğŸ“ æ”¯æŒèµ„æº

**æ–‡æ¡£å‚è€ƒ**:
- Kafka å®¢æˆ·ç«¯: https://docs.rs/rdkafka/
- Tokio å¼‚æ­¥è¿è¡Œæ—¶: https://tokio.rs/
- æ€§èƒ½æµ‹è¯•: Criterion.rs

**ä»£ç ç¤ºä¾‹ç›®å½•**:
- `/backend/user-service/src/services/notifications/kafka_consumer.rs` - æ¡†æ¶ä»£ç 
- `/backend/user-service/tests/` - å‚è€ƒæµ‹è¯•

**æ¯æ—¥ç«™ä¼š**:
- æ—¶é—´: 10:00 AM UTC
- å½¢å¼: 15 åˆ†é’Ÿ
- ä¸»é¢˜: è¿›åº¦ + é˜»å¡ç‚¹

---

## ğŸ’¡ å®ç°å»ºè®®

**æŒ‰ç…§ Linus åŸåˆ™**:

1. **æ•°æ®ç»“æ„ä¼˜å…ˆ**
   - è®¾è®¡æ¸…æ™°çš„ `KafkaNotification` ç»“æ„
   - æ‰¹å¤„ç†åº”è¯¥ç®€æ´æ˜äº†

2. **æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ**
   - æ‰€æœ‰æ¶ˆæ¯å¤„ç†æµç¨‹ç»Ÿä¸€
   - é”™è¯¯å¤„ç†ä½¿ç”¨é€šç”¨é‡è¯•æœºåˆ¶

3. **ç®€æ´æ‰§å¿µ**
   - æ¶ˆè´¹å¾ªç¯ä¸è¶…è¿‡ 50 è¡Œ
   - æ‰¹å¤„ç†ä¸è¶…è¿‡ 30 è¡Œ

4. **å‘åå…¼å®¹**
   - æ–°å¢å­—æ®µä½¿ç”¨ `Option<T>`
   - ä¿ç•™ç°æœ‰ API ç­¾å

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿ Let's go! ğŸš€**

*æœ€åæ›´æ–°: 2025-10-21 | é¢„è®¡å®Œæˆ: 2025-10-24*
